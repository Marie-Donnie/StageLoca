#+TITLE: Report for : Un intergiciel d’une base de données NewSQL qui considère la localité de l’application cliente
#+AUTHOR: Marie Delavergne


* 1st week
** Monday 15 January [2018-01-15 lun.]

*** Installation

- Solving administrative problems (account creations, etc.)
- Working in office B226

*** Preparations

- Cleaned boookmarks to be able to find them more rapidly
- Created folder and repo github for my work.
  + Added gitignore
  + Added tools
- WARNING : I can't run Vagrant without disabling secure boot


*** Readings

**** Spanner

- 2013
- DB
  + scalable
  + multi-version
  + globally-distributed
  + synchronously-replicated
  + google-made
- Reshard automatically data when the amount of data or the number of servers change
- Migrate automatically data across machines and DC
- Scale up to millions of machines, hundreds of DC and trillions of datarows
- Focus: managing cross-DC replicated data
- Evolved from a versioned key-value store to a temporal multi-version db
  + semi-relational db
  + data store with a commit timestamp
  + configurable garbage collector for old versions
- Replication configurations can be dynamically controlled at a fine grain
- More Spanner features that enable Spanner to support consistent backups, MapReduce executions and atomic schema updates
  + externally consistent reads and write
  + globally-conssistent reads across DB at a given timestamp
- Timestamps reflect serialization order
- Organized as a set of zones (unit of administrative deployment)
  + one zonemaster :: assigns data to spanservers
  + (100->n*1000) spanservers
  + tablet :: data structure (similar to Bigtable tablet abstraction)
  + per-zone location proxies :: used by clients to locate the spanservers assigned to serve their data
- Spanserver
  + serve data to clients
  + responsible for between 100 and 1000 instances of tablet
  + implements a single Paxos state machine on top of each tablet
  + logs every Paxos write twice (one in the tablet's log, once in the Paxos log)
- Transaction manager
  + If the transaction involves only one Paxos group, it can bypass the TM (lock table and Paxos provide transactionality)
  + If it involves more than one Paxos group, the groups' leaders coordinate to perform a two-phase commit
    - coordinator leader chosen and coordinator slaves
- Directory (bucket) : set of contiguous keys that share a common prefix
  + allows applications to control the locality of their data by choosing keys carefully
  + directories can be moved on-the-fly for different reasons (movedir)
- Megastore used by at least 300 Google applications
- Two-phase commit too expensive for performance and availability
- Every table must have an ordered set of one or more primary-key columns
- TrueTime represents time as a TTinterval (interval with bounded time uncertainty)

| Method      | Returns                              |
| TT.now()    | TTinterval: [earliest, latest]       |
| TT.after()  | true if t has definitely passed      |
| TT.before() | true if t has definitely not arrived |

- Two-phase commit can scale to up to 50 participants
- During experimentations on availability, we can see that only kill 'hard' a leader has a real impact on the reads completed
- Related works
  + VoltDB uses NewSQL

*** Meeting

- 14:15 with msimonin

**** Work
- Keystone with specific scenarii
  + tempest has more coverage (especially with the new decorator)


** Thursday 16 January [2018-01-16 mar.]

*** Openstack Cockroach Dev

- Resumed vagrant launched yesterday evening
- Used ~vagrant ssh~ to jump to the deployed machine

**** Running tempest
- Jumped to tempest folder
- Used ~testr init~ and then ~testr run --parallel tempest.scenario~ to run tests from [[https://www.openstack.org/assets/presentation-media/TempestScenarioTests-20140512.pdf][Tempest Scenarios Tests]]
  + Received some errors like these :
#+BEGIN_EXAMPLE
Traceback (most recent call last):
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/test_dvr.py", line 66, in test_vm_reachable_through_compute
    self._check_snat_port_connectivity()
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/test_dvr.py", line 32, in _check_snat_port_connectivity
    self._check_connectivity()
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/test_dvr.py", line 29, in _check_connectivity
    self.keypair['private_key'])
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/base.py", line 232, in check_connectivity
    ssh_client.test_connection_auth()
  File "tempest/lib/common/ssh.py", line 207, in test_connection_auth
    connection = self._get_ssh_connection()
  File "tempest/lib/common/ssh.py", line 121, in _get_ssh_connection
    password=self.password)
tempest.lib.exceptions.SSHTimeout: Connection to the 172.24.4.12 via SSH timed out.
User: cirros, Password: None
#+END_EXAMPLE
#+BEGIN_EXAMPLE
Traceback (most recent call last):
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/test_migration.py", line 200, in test_from_dvr_ha_to_dvr
    after_dvr=True, after_ha=False)
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/test_migration.py", line 114, in _test_migration
    router['id'], before_dvr, before_ha)
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/test_migration.py", line 80, in _wait_until_router_ports_ready
    router_id, const.DEVICE_OWNER_DVR_INTERFACE)
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/test_migration.py", line 64, in _wait_until_port_ready
    timeout=300, sleep=5)
  File "/opt/stack/neutron/neutron/common/utils.py", line 697, in wait_until_true
    raise WaitTimeout("Timed out after %d seconds" % timeout)
neutron.common.utils.WaitTimeout: Timed out after 300 seconds
#+END_EXAMPLE
- Might be because only keystone is supposed to work
- Stopped the run because it was running every tests for every components
- Rerun using ~tempest run --regex tempest.api.identity~
#+BEGIN_EXAMPLE
======
Totals
======
Ran: 143 tests in 134.0000 sec.
 - Passed: 128
 - Skipped: 10
 - Expected Fail: 0
 - Unexpected Success: 0
 - Failed: 5
Sum of execute time for each test: 251.9807 sec.

==============
Worker Balance
==============
 - Worker 0 (31 tests) => 0:01:54.281398
 - Worker 1 (28 tests) => 0:01:08.869696
 - Worker 2 (14 tests) => 0:01:39.594563
 - Worker 3 (24 tests) => 0:02:00.720647
 - Worker 4 (32 tests) => 0:01:53.721540
 - Worker 5 (14 tests) => 0:00:50.875559
#+END_EXAMPLE
- Have to see the logs, which is now in a binary file (journalctl)
- ~sudo journalctl --unit devstack@keytsone.service --since -5m~ to see the logs
- I can navigate using /ERR and n to go to the next
#+BEGIN_EXAMPLE
stack@contrib-jessie:~/tempest$ sudo journalctl --unit devstack@keytsone.service --since -5m
-- Logs begin at Tue 2018-01-16 10:15:51 GMT, end at Tue 2018-01-16 10:32:08 GMT. --
stack@contrib-jessie:~/tempest$
#+END_EXAMPLE

- Modified file in keystone folder ~keystone/identity/backends/sql.py~ :
  + Search for '@', copied ~ @oslo_db_api.wrap_db_retry(retry_on_deadlock=True)~
  + Added to the method that failed 'authenticate' (l. 58)
  + After that, I restart the service using ~sudo systemctl restart devstack@keystone~
  + And check if it is correctly loaded with ~sudo systemctl status devstack@keystone~

#+BEGIN_EXAMPLE
======
Totals
======
Ran: 142 tests in 197.0000 sec.
 - Passed: 132
 - Skipped: 10
 - Expected Fail: 0
 - Unexpected Success: 0
 - Failed: 0
Sum of execute time for each test: 435.4079 sec.

==============
Worker Balance
==============
 - Worker 0 (10 tests) => 0:01:49.532543
 - Worker 1 (17 tests) => 0:02:32.577647
 - Worker 2 (22 tests) => 0:02:36.304883
 - Worker 3 (37 tests) => 0:03:10.918512
 - Worker 4 (23 tests) => 0:02:42.695828
 - Worker 5 (33 tests) => 0:02:41.024460

#+END_EXAMPLE

- When doing my PR, I discovered there was a branch called 'deadlock-retry' so I've checked it:
  + turns out there was different changes on it, and the decorator (wrapper) was used on ~_record_failed_auth~ and ~update_user~
  + but when I reran the tests on this branch I got
#+BEGIN_EXAMPLE
======
Totals
======
Ran: 132 tests in 180.0000 sec.
- Passed: 120
- Skipped: 10
- Expected Fail: 0
- Unexpected Success: 0
- Failed: 2
Sum of execute time for each test: 378.7295 sec.

==============
Worker Balance
==============
- Worker 0 (9 tests) => 0:01:30.253865
- Worker 1 (32 tests) => 0:02:36.105035
- Worker 2 (20 tests) => 0:02:24.938662
- Worker 3 (26 tests) => 0:02:29.701283
- Worker 4 (18 tests) => 0:02:09.142470
- Worker 5 (27 tests) => 0:02:47.248556
#+END_EXAMPLE

- After asking my tutor, turns out that the branch was an old one so I just made my PR to cockroachdb/pike

*** Readings

**** Raft

- Goal is to have a result equivalent to Paxos, but more understandable and easier to learn
- Consensus algorithms "allow a collection of machines to work as a coherent group that can survive the failures of some of its members"
- Most implementations of consensus are based on or influenced by Paxos
- Raft uses techniques to improve understandability
  + decomposition: leader election, log replication, safety
  + state space reduction: reduce the degree of nondeterminism and ways servers can be inconsistent with each other
- New features
  + Strong leader :: stronger form of leadership
  + Leader election :: randomized timers
  + Membership changes :: two different configurations overlap when changing the set of servers in a cluster
- Safety properties formally specified and proven

***** Replicated state machine problem

- Consensus algorithms are used in the context of RSM
  + Replicated State Machines:: state machines in a collection of servers compute identical copies of the same state and continue operating even if some of the servers are down
  + It is used to solve a variety of fault tolerance problems in distributed systems

#+CAPTION: RSM architecture from the Raft article
#+NAME: fig:raft_RSM_architecture
[[images/Raft_RSM_architecture.png]]

- Each server stores a log containing a series of commands executed in order by he state machine associated
  + The commands are in the same order on each log -> same sequence executed on all state machines -> same state computed and same sequence of output (because of determinism)
- The replicated log is kept consistent by the consensus algorithm
- Properties of the algorithm
  + safety under all non-Byzantine conditions including network delays, partitions, packet loss, duplication and re-ordering
  + availability if a majority of servers are operational and communicate with each other and clients. (n/2 +1)
  + consistency of the logs independent of timing
  + speed: for most cases, a given command is completed when a majority of the cluster has responded to a single round of remote procedure calls

***** Strengths and weaknesses of Paxos

- Largely used, at least as a starting point
- Different level of Paxos:
  + single-decree Paxos:: able to reach agreement on a single decision (like a single replicated log entry)
  + multi-Paxos:: multiple instances of the former protocol to facilitate a series of decisions (such as an entire log)
- Ensures safety and liveness
- Supports changes in cluster membership
- Two major drawbacks
  + awfully  difficult to understand
  + no good foundation to make practical implementations
- As a consequence, implementations are usually extremely different from the Paxos theory, especially in terms of architecture
  + time consuming and error-prone
  + worse: since the implementations are too different, the correctness of Paxos can't be verified

***** General approach to understandability

- Raft had to:
  + provide a complete and practical foundation for system building
  + be safe under all conditions
  + be available under typical operating conditions
  + be efficient for common operations
  + be UNDERSTANDABLE
    - by a large audience
    - to make possible the development of extensions
- To make it understandable:
  + each time a choice had to be made, it was always for understandability
  + two techniques were used, as seen previously (decomposition and state space reduction)

***** Raft consensus algorithm

1. Election of a leader
   - if a leader fails or is disconnected, a new leader is elected
   - at any time each server is either:
     + leader :: only one
       - sends periodic heartbeat to followers as soon as he is elected to prevent election
     + follower :: passive, they respond to requests from leaders and candidates
     + candidate :: used to elect a new leader
   - if a follower receives no communication for a period of time (election timeout), it begins the election to choose a new leader
     + the follower increments its current term, becomes a candidate, votes for itself and sends RequestVote RPC to every servers in the cluster
       - a candidate wins the election if it receives votes from a majority of servers for the same term
       - followers vote for one candidate on a first-come first-served basis
       - if a candidate gets a signal from a leader and the term received is at least as large as the candidate current term, the candidate returns to follower
       - to prevent different rounds of elections (if many followers become candidates at the same time), election timeouts are chosen randomly from a fixed interval
2. Give responsibility for managing the replicated log to this leader
3. Leader accepts log entries from clients
4. Leader replicates them to other servers
5. Leader tells the servers when they can apply new log entries to their state machines


- Time is divided into /terms/ of arbitrary length
  + Numbered with consecutive integers; each server stores a current term (increasing monotonically)
  + each term begins with an election where one or more candidates attempt to become leader
  + if an election ends with a split vote, the term ends and a new one begins
  + Serves as a logical clock
    - if 2 servers communicate and don't have the same term value, they take the largest one
    - if a candidate or leader discovers this way that his term has ended, he becomes a follower
    - if the server receives a request with an older term, it rejects the request

- When receiving a new entry, the leader appends the command to its log as a neww entry
  + it sends the order to append the entries to the other servers to replicate the entry
- An entry of a log stores a command, a term number when the entry was received by the leader and an integer indentifying its position in the log
- The leader chooses when a entry is commited, i.e. when an entry has replicated to a majority of servers. This commit also commits all preceding entries in the leader's log (including entries from former leaders).
- Log matching properties ([[fig:raft_properties]]):
  + if 2 entries in different logs have the same index and term, they store the same command
  + if 2 entries in different logs have the same index and term, then the logs are identical in all preceding entries
- The leader maintain a nextIndex for each follower so he knows which entry it will send
- Election restriction:
  + prevents candidate from winning an election unless its log contains all committed entries
  + a follower denies a candidate vote if its own log is more up-to-date
    - if the logs have last entries with different terms, the log with the later term is more u-t-d
    - if the logs have the same terms as last entries, whichever log is longer is more u-t-d
- Raft handles followers failure by retrying indefinitely the RPCs.
  + RPCs are idempotent; a request that includes log entries already present is ignored
- Timing is crucial only for leader election
  + timing requirement: broadcastTime << electionTimeout << MTBF (average time between failures for a single server)
    - electionTimeout is the only thing chosen : usually, between 10 and 500ms
- Configuration changes comes with two phases
  + joint consensus :: combines both configurations
    - log entries are replicated to all servers in both configurations
    - any server from either configuration can be a leader
    - agreement requires separate majorities from *both* the old and new configurations
    - allows the service of clients even when configuration changes
    - leader log entry for joint consensus C_{old,new} and replicates it
    - servers only uses the latest configuration in its log, whether the entry is committed or not
    - if a leader crash (using the C_{old,new} rules), the new leader may be chosen under C_{old} or C_{old,new} (C_{new} cannot make unilateral decisions during this period)
  + once C_{old,new} has been committed, neither old nor new can make decisions without receiving approval from the other
    - only servers with the C_{old,new} entry can be leader
    - this leader create a log entry for Cnew and replicates it
  + when the new configuration has been commited, servers not in the new configuration can be shut down
  + there are no time when C_{old} or C_{new} can make unilateral decisions
  + when new servers are added, they are non-voting members (not counted for majority)
    - when they have the correct replicated log, the reconfiguration can begin
  + if the leader is not part of the new configuration, it will become follower has soon as he committed C_{new}, and will not count for votes
  + to prevent removed servers from disrupting with votes, the followers disregards the RequestVote RPC

#+CAPTION: A -not-so- condensed summary of the Raft consensus algorithm
#+NAME: fig:raft_conso_algo
[[images/Raft_conso_algo.pdf]]


#+CAPTION: Raft ensured properties
#+NAME: fig:raft_properties
[[images/Raft_properties.png]]


- Clients and log compaction can be found in the [[https://ramcloud.stanford.edu/raft.pdf][extended version of the paper]].

***** Raft evaluation

- Raft implementation contains ~2000 lines of C++ code
- available on [[http://github.com/logcabin/logcabin][Github]]
- easy to understand
- correctness uses [[fig:raft_conso_algo]] and proven in [[https://ramcloud.stanford.edu/~ongaro/thesis.pdf][proof of the State Machine Safety property]]
- performance similar to other consensus algorithms
- recommands using a conservative election timeout such as 150-300ms

***** Related work

- Lamport description of Paxos
- Elaborations of Paxos
- Systems that implement consensus algorithms (Chubby, Zookeeper and Spanner)
- Performance optimizations that can be applied to Paxos
- Viewstamped Replication from Oki and Liskov

***** Conclusion

- Better foundation for system building


* Readings

** Preliminary
- [[https://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf][Spanner: Google’s Globally-Distributed Database]]
- [[https://www.usenix.org/system/files/conference/atc14/atc14-paper-ongaro.pdf][In Search of an Understandable Consensus Algorithm]]
- [[https://github.com/cockroachdb/cockroach/blob/master/docs/design.md][CockroachDB doc]]
- [[https://www.youtube.com/watch?v=6OFeuNy39Qg][The hows and whys of a distributed SQL database]] by Alex Robinson
- [[http://vitess.io/][Vitess site]]
- [[https://beyondtheclouds.github.io/blog/openstack/cockroachdb/2017/12/22/a-poc-of-openstack-keystone-over-cockroachdb.html][BTC blog article about Keystone over CockroachDB]]

** Others
- [[https://en.wikipedia.org/wiki/Paxos_(computer_science)][Paxos]]

* How to

** Org mode

To add a date not added to agenda:
#+BEGIN_SRC
Ctrl-c !
#+END_SRC
To demote current subtree by one level:
#+BEGIN_SRC
Alt-Shift-Left
#+END_SRC


** Using Rally & Tempest

*** Tempest

To run only keystone tests:
#+BEGIN_SRC
tempest run --regex tempest.api.identity
#+END_SRC


** Using devstack

Since it's not using screen anymore, everything is in systemctl.

To restart a service:
#+BEGIN_SRC
sudo systemctl restart devstack@SERVICE_NAME
#+END_SRC
To know the status of a service:
#+BEGIN_SRC
sudo systemctl status devstack@SERVICE_NAME
#+END_SRC


** Other

Cut pages in pdf (from [[https://askubuntu.com/questions/221962/how-can-i-extract-a-page-range-a-part-of-a-pdf][Ask Ubuntu]]):
#+BEGIN_SRC
pdftk full-pdf.pdf cat 12-15 output outfile_p12-15.pdf
#+END_SRC
