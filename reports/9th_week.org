#+TITLE: Report for : Un intergiciel d’une base de données NewSQL qui considère la localité de l’application cliente -- 8th week --
#+AUTHOR: Marie Delavergne

* Monday 12 March [2018-03-12 lun.]

- Finished late friday, didn't have time to say everything I had to say

- We tried to define important factors that will impact the most the tests:
  + the number of nodes is clearly important:
    - we will try with 1, 5, 50, then we will use 'binary search' if need : 25, 12, etc.
  + delay: LAN, 5, 25, 50
  + maybe quorum size for CockroachDB

- We defined the scenarios we want to run, removing the ~| shuffle(seed=inventory_hostname)~
  + authenticate-user-and-validate-token.yaml
  + create-add-and-list-user-roles.yaml
  + create-and-list-tenants.yaml
  + get-entities.yaml
  + create-and-update-user.yaml
  + create-user-update-password.yaml
  + create-user-set-enabled-and-delete.yaml
  + create-and-list-users.yaml

#+BEGIN_EXAMPLE
./juice.py rally --files keystone/authenticate-user-and-validate-token.yaml --files keystone/create-add-and-list-user-roles.yaml --files keystone/create-and-list-tenants.yaml --files keystone/get-entities.yaml --files keystone/create-and-update-user.yaml --files keystone/create-user-update-password.yaml --files keystone/create-user-set-enabled-and-delete.yaml --files keystone/create-and-list-users.yaml
#+END_EXAMPLE


- For now, we will get back to only one Rally

- Trying to find the point when MariaDB doesn't cope with latency

- Launching nightly exp with tmux and screen:
#+BEGIN_EXAMPLE
Ctrl-a n to switch between jobs
Ctrl-b d to quit tmux
#+END_EXAMPLE


* Tuesday 13 March [2018-03-13 mar.]

- Seems that nothing worked:
  + only one folder for deployment, with only one file in it, the =env=, which isn't even filled:
#+BEGIN_EXAMPLE
config: {}
config_file: ''
cwd: /home/madelavergne/juice
nodes: {}
phase: ''
resultdir: /home/madelavergne/juice/enos_2018-03-12T18:55:46.270710
user: ''
#+END_EXAMPLE

- I tried to deploy on 10 nodes to test but I got an error on every node
#+BEGIN_EXAMPLE
failed: [grisou-39.nancy.grid5000.fr] (item=[u'grisou-35.nancy.grid5000.fr', u'grisou-42.nancy.grid5000.fr', u'grisou-4.nancy.grid5000.fr', u'grisou-1.nancy.grid5000.fr', u'grisou-38.nancy.grid5000.fr', u'grisou-36.nancy.grid5000.fr', u'grisou-37.nancy.grid5000.fr', u'grisou-40.nancy.grid5000.fr', u'grisou-41.nancy.grid5000.fr', u'grisou-39.nancy.grid5000.fr']) => {"failed": true, "item": ["grisou-35.nancy.grid5000.fr", "grisou-42.nancy.grid5000.fr", "grisou-4.nancy.grid5000.fr", "grisou-1.nancy.grid5000.fr", "grisou-38.nancy.grid5000.fr", "grisou-36.nancy.grid5000.fr", "grisou-37.nancy.grid5000.fr", "grisou-40.nancy.grid5000.fr", "grisou-41.nancy.grid5000.fr", "grisou-39.nancy.grid5000.fr"], "msg": "AnsibleUndefinedVariable: 'dict object' has no attribute 'ipv4'"}
#+END_EXAMPLE
- Modified conf file to take eth0/1... depending on database network


- After testing MariaDB on 10 nodes varying the latency from 0 to 50 and 150 ms, I check the results...
 And there rougly the same.
- Checking the pings:
#+BEGIN_EXAMPLE
root@grisou-17:~# ping 10.16.76.66
PING 10.16.76.66 (10.16.76.66) 56(84) bytes of data.
64 bytes from 10.16.76.66: icmp_seq=1 ttl=64 time=0.085 ms
64 bytes from 10.16.76.66: icmp_seq=2 ttl=64 time=0.047 ms
64 bytes from 10.16.76.66: icmp_seq=3 ttl=64 time=0.057 ms
64 bytes from 10.16.76.66: icmp_seq=4 ttl=64 time=0.061 ms
64 bytes from 10.16.76.66: icmp_seq=5 ttl=64 time=0.046 ms
64 bytes from 10.16.76.66: icmp_seq=6 ttl=64 time=0.049 ms
--- 10.16.76.66 ping statistics ---
6 packets transmitted, 6 received, 0% packet loss, time 5114ms
rtt min/avg/max/mdev = 0.046/0.057/0.085/0.015 ms
root@grisou-17:~# ping 172.16.72.6
PING 172.16.72.6 (172.16.72.6) 56(84) bytes of data.
64 bytes from 172.16.72.6: icmp_seq=1 ttl=64 time=300 ms
64 bytes from 172.16.72.6: icmp_seq=2 ttl=64 time=300 ms
--- 172.16.72.6 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1000ms
rtt min/avg/max/mdev = 300.092/300.109/300.126/0.017 ms
#+END_EXAMPLE
- There is indeed the latency applied, but it should be the opposite : 10... is the address for the databases and 172... is for control, so of course there is no difference.
- Trying to debug this
  + should have paid more attention, it was already visible in emulate:
#+BEGIN_EXAMPLE
TASK [utils : Preparing htf for {{ item.device }}] ****************************************************************************************************************************************************************
changed: [grisou-9.nancy.grid5000.fr] => (item={'macaddress': u'24:6e:96:02:97:a8', 'features': {}, 'type': u'ether', 'pciid': u'0000:01:00.0', 'module': u'ixgbe', 'mtu': 1500, 'device': u'eth0', 'promisc': False, 'ipv4': {'broadcast': u'172.16.79.255', 'netmask': u'255.255.240.0', 'network': u'172.16.64.0', 'address': u'172.16.72.9'}, 'ipv6': [{'scope': u'link', 'prefix': u'64', 'address': u'fe80::266e:96ff:fe02:97a8'}], 'active': True, 'speed': 10000})
#+END_EXAMPLE

#+BEGIN_EXAMPLE

'grisou-17.nancy.grid5000.fr':
     {'devices':
           [{'macaddress': '24:6e:96:02:a1:50',
		'features': {},
		'type': 'ether',
		'pciid': '0000:01:00.0',
		'module': 'ixgbe',
		'mtu': 1500,
		'device': 'eth0',
		'promisc': False,
		'ipv4': {'broadcast': '172.16.79.255',
		         'netmask': '255.255.240.0',
			 'network': '172.16.64.0',
			 'address': '172.16.72.17'},
		'ipv6': [{'scope': 'link',
		          'prefix': '64',
			  'address': 'fe80::266e:96ff:fe02:a150'}],
		'active': True, 'speed': 10000}],
     'all_ipv4_addresses':
           ['172.16.72.17', '10.16.76.77', '172.17.0.1'],
     'tc': [{'loss': '0', 'target': '172.16.72.17', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '10.16.76.77', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '10.16.76.104', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '172.16.72.44', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '172.16.72.42', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '10.16.76.102', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '172.16.72.41', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '10.16.76.101', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '10.16.76.62', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '172.16.72.2', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '10.16.76.67', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '172.16.72.7', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '172.16.72.6', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '10.16.76.66', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '172.16.72.37', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '10.16.76.97', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '172.16.72.40', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '10.16.76.100', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '172.16.72.8', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'},
		{'loss': '0', 'target': '10.16.76.68', 'delay': '150ms', 'source': 'grisou-17.nancy.grid5000.fr', 'rate': '10gbit', 'device': 'eth0'}]
},
#+END_EXAMPLE


* Wednesday 14 March [2018-03-14 mer.]

- Wanted to launch an experiment on 10 nodes but I first cleaned up my processes because there was a lot of running ssh
  + I will have to figure out why they stayed opened

- We searched yesterday with Jonathan why I need to enter my password when deploying with no luck

- I think I found out why my experiments didn't work monday while trying to do the same thing on the same nodes (the others were taken):
#+BEGIN_EXAMPLE
Traceback (most recent call last):
 File "./juice.py", line 370, in <module>
   doc_lookup(args['<command>'], argv)
 File "/home/madelavergne/juice/utils/doc.py", line 29, in doc_lookup
   return fn(**docopt(fn.__doc__, argv=argv))
 File "/home/madelavergne/juice/utils/doc.py", line 18, in decorated
   fn(*args, **kwargs)
 File "/home/madelavergne/juice/venv/local/lib/python2.7/site-packages/enoslib/task.py", line 50, in decorated
   fn(*args, **kwargs)
 File "./juice.py", line 340, in exp
   deploy(conf, db, locality)
 File "/home/madelavergne/juice/utils/doc.py", line 18, in decorated
   fn(*args, **kwargs)
 File "./juice.py", line 86, in deploy
   g5k(config=config)
 File "/home/madelavergne/juice/utils/doc.py", line 18, in decorated
   fn(*args, **kwargs)
 File "/home/madelavergne/juice/venv/local/lib/python2.7/site-packages/enoslib/task.py", line 50, in decorated
   fn(*args, **kwargs)
 File "./juice.py", line 100, in g5k
   roles, networks = provider.init(force_deploy=force)
 File "/home/madelavergne/juice/venv/local/lib/python2.7/site-packages/enoslib/infra/enos_g5k/provider.py", line 161, in init
   r.launch(**self.provider_conf)
 File "/home/madelavergne/juice/venv/local/lib/python2.7/site-packages/enoslib/infra/enos_g5k/api.py", line 83, in launch
   self.configure_network(**kwargs)
 File "/home/madelavergne/juice/venv/local/lib/python2.7/site-packages/enoslib/infra/enos_g5k/api.py", line 140, in configure_network
   utils.mount_nics(self.c_resources)
 File "/home/madelavergne/juice/venv/local/lib/python2.7/site-packages/enoslib/infra/enos_g5k/utils.py", line 81, in mount_nics
   _mount_secondary_nics(desc, networks)
 File "/home/madelavergne/juice/venv/local/lib/python2.7/site-packages/enoslib/infra/enos_g5k/utils.py", line 104, in _mount_secondary_nics
   nic = nics[idx]
IndexError: list index out of range
#+END_EXAMPLE
- It seems that there are not enough nics on Graphene cluster
  + after checking, there is actually enough nics BUT it seems that only one interface is configured, the others don't have ips

- Got the same error on Genepi

- MariaDB config bugs every time the first time I deploy. It might be a problem related to what interface is configured for the first run


- Trying to match configurations for Galera and Cockroach, looking at:
  + [[https://www.cockroachlabs.com/docs/stable/frequently-asked-questions.html][Cockroach FAQ]]
  + [[https://www.cockroachlabs.com/docs/stable/start-a-node.html][Cockroach doc about starting a node]]
  + [[https://www.cockroachlabs.com/docs/stable/cockroachdb-in-comparison.html][Cockroach comparison to other DB]]
  + [[https://mariadb.com/kb/en/library/galera-cluster-system-variables/][MariaDB/Galera cluster variables]]


- irc meeting (#openstack-meeting)
  + I will have to make a performance doc like Matthieu made

- My tests didn't work because the latency is still reversed. I will have to work on that.


* Thursday 15 March [2018-03-15 jeu.]

- Same problem with cockroachdb

#+BEGIN_EXAMPLE
fatal: [grisou-37.nancy.grid5000.fr]: FAILED! => {"failed": true, "msg": "The task includes an option with an undefined variable. The error was: 'dict object' has no attribute 'ipv4'\n\nThe error appears to have been in '/home/madelavergne/juice/ansible/roles/cockroachdb/tasks/deploy.yml': line 26, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Start other cockroachdb nodes\n  ^ here\n"}
#+END_EXAMPLE
- Did the same workaround but I may have to find something better


- Searching in the enoslib for a solution to the latency not on the right network [[https://github.com/BeyondTheClouds/enoslib/blob/master/enoslib/api.py][enoslib api]]
  + used it before, so I'm putting this here: [[https://stackoverflow.com/questions/5445970/how-to-properly-print-a-list][how to properly print a list]]
  + l.774 : select devices, but there is only eth0 in ips.txt
  + don't know why, ={{ enos_devices}}= in debug is fine but when templated, there is only eth0
    - replace =enos_devices= in template by =hostvars[host]['enos_devices']=, it seems to have worked at least to consider all devices
  + first step ok, but it would still add latency on both networks
    - have to figure out how to do that

- It took some sweet time, BUT: from a node to the dbmasternode:
#+BEGIN_EXAMPLE
root@grisou-4:~# ping 172.16.72.43
PING 172.16.72.43 (172.16.72.43) 56(84) bytes of data.
64 bytes from 172.16.72.43: icmp_seq=1 ttl=64 time=0.133 ms
64 bytes from 172.16.72.43: icmp_seq=2 ttl=64 time=0.062 ms
64 bytes from 172.16.72.43: icmp_seq=3 ttl=64 time=0.053 ms
--- 172.16.72.43 ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2029ms
rtt min/avg/max/mdev = 0.053/0.082/0.133/0.037 ms
root@grisou-4:~# ping 10.16.12.103
PING 10.16.12.103 (10.16.12.103) 56(84) bytes of data.
64 bytes from 10.16.12.103: icmp_seq=1 ttl=64 time=300 ms
64 bytes from 10.16.12.103: icmp_seq=2 ttl=64 time=300 ms
--- 10.16.12.103 ping statistics ---
3 packets transmitted, 2 received, 33% packet loss, time 1999ms
rtt min/avg/max/mdev = 300.101/300.115/300.130/0.548 ms

#+END_EXAMPLE


- To watch network usage:
#+BEGIN_SRC
apt install net-tools
watch ifconfig
watch ifconfig eth1
#+END_SRC
- Also see =iftop=
