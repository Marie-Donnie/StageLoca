#+TITLE: Report for : Un intergiciel d’une base de données NewSQL qui considère la localité de l’application cliente
#+AUTHOR: Marie Delavergne


* 1st week
** Monday 15 January [2018-01-15 lun.]

*** Installation

- Solving administrative problems (account creations, etc.)
- Working in office B226

*** Preparations

- Cleaned boookmarks to be able to find them more rapidly
- Created folder and repo github for my work.
  + Added gitignore
  + Added tools
- WARNING : I can't run Vagrant without disabling secure boot


*** Readings

**** Spanner

- 2013
- DB
  + scalable
  + multi-version
  + globally-distributed
  + synchronously-replicated
  + google-made
- Reshard automatically data when the amount of data or the number of servers change
- Migrate automatically data across machines and DC
- Scale up to millions of machines, hundreds of DC and trillions of datarows
- Focus: managing cross-DC replicated data
- Evolved from a versioned key-value store to a temporal multi-version db
  + semi-relational db
  + data store with a commit timestamp
  + configurable garbage collector for old versions
- Replication configurations can be dynamically controlled at a fine grain
- More Spanner features that enable Spanner to support consistent backups, MapReduce executions and atomic schema updates
  + externally consistent reads and write
  + globally-conssistent reads across DB at a given timestamp
- Timestamps reflect serialization order
- Organized as a set of zones (unit of administrative deployment)
  + one zonemaster :: assigns data to spanservers
  + (100->n*1000) spanservers
  + tablet :: data structure (similar to Bigtable tablet abstraction)
  + per-zone location proxies :: used by clients to locate the spanservers assigned to serve their data
- Spanserver
  + serve data to clients
  + responsible for between 100 and 1000 instances of tablet
  + implements a single Paxos state machine on top of each tablet
  + logs every Paxos write twice (one in the tablet's log, once in the Paxos log)
- Transaction manager
  + If the transaction involves only one Paxos group, it can bypass the TM (lock table and Paxos provide transactionality)
  + If it involves more than one Paxos group, the groups' leaders coordinate to perform a two-phase commit
    - coordinator leader chosen and coordinator slaves
- Directory (bucket) : set of contiguous keys that share a common prefix
  + allows applications to control the locality of their data by choosing keys carefully
  + directories can be moved on-the-fly for different reasons (movedir)
- Megastore used by at least 300 Google applications
- Two-phase commit too expensive for performance and availability
- Every table must have an ordered set of one or more primary-key columns
- TrueTime represents time as a TTinterval (interval with bounded time uncertainty)

| Method      | Returns                              |
| TT.now()    | TTinterval: [earliest, latest]       |
| TT.after()  | true if t has definitely passed      |
| TT.before() | true if t has definitely not arrived |

- Two-phase commit can scale to up to 50 participants
- During experimentations on availability, we can see that only kill 'hard' a leader has a real impact on the reads completed
- Related works
  + VoltDB uses NewSQL

*** Meeting

- 14:15 with msimonin

**** Work
- Keystone with specific scenarii
  + tempest has more coverage (especially with the new decorator)


** Thursday 16 January [2018-01-16 mar.]

*** Openstack Cockroach Dev

- Resumed vagrant launched yesterday evening
- Used ~vagrant ssh~ to jump to the deployed machine

**** Running tempest
- Jumped to tempest folder
- Used ~testr init~ and then ~testr run --parallel tempest.scenario~ to run tests from [[https://www.openstack.org/assets/presentation-media/TempestScenarioTests-20140512.pdf][Tempest Scenarios Tests]]
  + Received some errors like these :
#+BEGIN_EXAMPLE
Traceback (most recent call last):
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/test_dvr.py", line 66, in test_vm_reachable_through_compute
    self._check_snat_port_connectivity()
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/test_dvr.py", line 32, in _check_snat_port_connectivity
    self._check_connectivity()
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/test_dvr.py", line 29, in _check_connectivity
    self.keypair['private_key'])
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/base.py", line 232, in check_connectivity
    ssh_client.test_connection_auth()
  File "tempest/lib/common/ssh.py", line 207, in test_connection_auth
    connection = self._get_ssh_connection()
  File "tempest/lib/common/ssh.py", line 121, in _get_ssh_connection
    password=self.password)
tempest.lib.exceptions.SSHTimeout: Connection to the 172.24.4.12 via SSH timed out.
User: cirros, Password: None
#+END_EXAMPLE
#+BEGIN_EXAMPLE
Traceback (most recent call last):
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/test_migration.py", line 200, in test_from_dvr_ha_to_dvr
    after_dvr=True, after_ha=False)
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/test_migration.py", line 114, in _test_migration
    router['id'], before_dvr, before_ha)
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/test_migration.py", line 80, in _wait_until_router_ports_ready
    router_id, const.DEVICE_OWNER_DVR_INTERFACE)
  File "/opt/stack/neutron/neutron/tests/tempest/scenario/test_migration.py", line 64, in _wait_until_port_ready
    timeout=300, sleep=5)
  File "/opt/stack/neutron/neutron/common/utils.py", line 697, in wait_until_true
    raise WaitTimeout("Timed out after %d seconds" % timeout)
neutron.common.utils.WaitTimeout: Timed out after 300 seconds
#+END_EXAMPLE
- Might be because only keystone is supposed to work
- Stopped the run because it was running every tests for every components
- Rerun using ~tempest run --regex tempest.api.identity~
#+BEGIN_EXAMPLE
======
Totals
======
Ran: 143 tests in 134.0000 sec.
 - Passed: 128
 - Skipped: 10
 - Expected Fail: 0
 - Unexpected Success: 0
 - Failed: 5
Sum of execute time for each test: 251.9807 sec.

==============
Worker Balance
==============
 - Worker 0 (31 tests) => 0:01:54.281398
 - Worker 1 (28 tests) => 0:01:08.869696
 - Worker 2 (14 tests) => 0:01:39.594563
 - Worker 3 (24 tests) => 0:02:00.720647
 - Worker 4 (32 tests) => 0:01:53.721540
 - Worker 5 (14 tests) => 0:00:50.875559
#+END_EXAMPLE
- Have to see the logs, which is now in a binary file (journalctl)
- ~sudo journalctl --unit devstack@keytsone.service --since -5m~ to see the logs
- I can navigate using /ERR and n to go to the next
#+BEGIN_EXAMPLE
stack@contrib-jessie:~/tempest$ sudo journalctl --unit devstack@keytsone.service --since -5m
-- Logs begin at Tue 2018-01-16 10:15:51 GMT, end at Tue 2018-01-16 10:32:08 GMT. --
stack@contrib-jessie:~/tempest$
#+END_EXAMPLE

- Modified file in keystone folder ~keystone/identity/backends/sql.py~ :
  + Search for '@', copied ~ @oslo_db_api.wrap_db_retry(retry_on_deadlock=True)~
  + Added to the method that failed 'authenticate' (l. 58)
  + After that, I restart the service using ~sudo systemctl restart devstack@keystone~
  + And check if it is correctly loaded with ~sudo systemctl status devstack@keystone~

#+BEGIN_EXAMPLE
======
Totals
======
Ran: 142 tests in 197.0000 sec.
 - Passed: 132
 - Skipped: 10
 - Expected Fail: 0
 - Unexpected Success: 0
 - Failed: 0
Sum of execute time for each test: 435.4079 sec.

==============
Worker Balance
==============
 - Worker 0 (10 tests) => 0:01:49.532543
 - Worker 1 (17 tests) => 0:02:32.577647
 - Worker 2 (22 tests) => 0:02:36.304883
 - Worker 3 (37 tests) => 0:03:10.918512
 - Worker 4 (23 tests) => 0:02:42.695828
 - Worker 5 (33 tests) => 0:02:41.024460

#+END_EXAMPLE

- When doing my PR, I discovered there was a branch called 'deadlock-retry' so I've checked it:
  + turns out there was different changes on it, and the decorator (wrapper) was used on ~_record_failed_auth~ and ~update_user~
  + but when I reran the tests on this branch I got
#+BEGIN_EXAMPLE
======
Totals
======
Ran: 132 tests in 180.0000 sec.
- Passed: 120
- Skipped: 10
- Expected Fail: 0
- Unexpected Success: 0
- Failed: 2
Sum of execute time for each test: 378.7295 sec.

==============
Worker Balance
==============
- Worker 0 (9 tests) => 0:01:30.253865
- Worker 1 (32 tests) => 0:02:36.105035
- Worker 2 (20 tests) => 0:02:24.938662
- Worker 3 (26 tests) => 0:02:29.701283
- Worker 4 (18 tests) => 0:02:09.142470
- Worker 5 (27 tests) => 0:02:47.248556
#+END_EXAMPLE

- After asking my tutor, turns out that the branch was an old one so I just made my PR to cockroachdb/pike

*** Readings

**** Raft

- Goal is to have a result equivalent to Paxos, but more understandable and easier to learn
- Consensus algorithms "allow a collection of machines to work as a coherent group that can survive the failures of some of its members"
- Most implementations of consensus are based on or influenced by Paxos
- Raft uses techniques to improve understandability
  + decomposition: leader election, log replication, safety
  + state space reduction: reduce the degree of nondeterminism and ways servers can be inconsistent with each other
- New features
  + Strong leader :: stronger form of leadership
  + Leader election :: randomized timers
  + Membership changes :: two different configurations overlap when changing the set of servers in a cluster
- Safety properties formally specified and proven

***** Replicated state machine problem

- Consensus algorithms are used in the context of RSM
  + Replicated State Machines:: state machines in a collection of servers compute identical copies of the same state and continue operating even if some of the servers are down
  + It is used to solve a variety of fault tolerance problems in distributed systems

#+CAPTION: RSM architecture from the Raft article
#+NAME: fig:raft_RSM_architecture
[[images/Raft_RSM_architecture.png]]

- Each server stores a log containing a series of commands executed in order by he state machine associated
  + The commands are in the same order on each log -> same sequence executed on all state machines -> same state computed and same sequence of output (because of determinism)
- The replicated log is kept consistent by the consensus algorithm
- Properties of the algorithm
  + safety under all non-Byzantine conditions including network delays, partitions, packet loss, duplication and re-ordering
  + availability if a majority of servers are operational and communicate with each other and clients. (n/2 +1)
  + consistency of the logs independent of timing
  + speed: for most cases, a given command is completed when a majority of the cluster has responded to a single round of remote procedure calls

***** Strengths and weaknesses of Paxos

- Largely used, at least as a starting point
- Different level of Paxos:
  + single-decree Paxos:: able to reach agreement on a single decision (like a single replicated log entry)
  + multi-Paxos:: multiple instances of the former protocol to facilitate a series of decisions (such as an entire log)
- Ensures safety and liveness
- Supports changes in cluster membership
- Two major drawbacks
  + awfully  difficult to understand
  + no good foundation to make practical implementations
- As a consequence, implementations are usually extremely different from the Paxos theory, especially in terms of architecture
  + time consuming and error-prone
  + worse: since the implementations are too different, the correctness of Paxos can't be verified

***** General approach to understandability

- Raft had to:
  + provide a complete and practical foundation for system building
  + be safe under all conditions
  + be available under typical operating conditions
  + be efficient for common operations
  + be UNDERSTANDABLE
    - by a large audience
    - to make possible the development of extensions
- To make it understandable:
  + each time a choice had to be made, it was always for understandability
  + two techniques were used, as seen previously (decomposition and state space reduction)

***** Raft consensus algorithm

1. Election of a leader
   - if a leader fails or is disconnected, a new leader is elected
   - at any time each server is either:
     + leader :: only one
       - sends periodic heartbeat to followers as soon as he is elected to prevent election
     + follower :: passive, they respond to requests from leaders and candidates
     + candidate :: used to elect a new leader
   - if a follower receives no communication for a period of time (election timeout), it begins the election to choose a new leader
     + the follower increments its current term, becomes a candidate, votes for itself and sends RequestVote RPC to every servers in the cluster
       - a candidate wins the election if it receives votes from a majority of servers for the same term
       - followers vote for one candidate on a first-come first-served basis
       - if a candidate gets a signal from a leader and the term received is at least as large as the candidate current term, the candidate returns to follower
       - to prevent different rounds of elections (if many followers become candidates at the same time), election timeouts are chosen randomly from a fixed interval
2. Give responsibility for managing the replicated log to this leader
3. Leader accepts log entries from clients
4. Leader replicates them to other servers
5. Leader tells the servers when they can apply new log entries to their state machines


- Time is divided into /terms/ of arbitrary length
  + Numbered with consecutive integers; each server stores a current term (increasing monotonically)
  + each term begins with an election where one or more candidates attempt to become leader
  + if an election ends with a split vote, the term ends and a new one begins
  + Serves as a logical clock
    - if 2 servers communicate and don't have the same term value, they take the largest one
    - if a candidate or leader discovers this way that his term has ended, he becomes a follower
    - if the server receives a request with an older term, it rejects the request

- When receiving a new entry, the leader appends the command to its log as a neww entry
  + it sends the order to append the entries to the other servers to replicate the entry
- An entry of a log stores a command, a term number when the entry was received by the leader and an integer indentifying its position in the log
- The leader chooses when a entry is commited, i.e. when an entry has replicated to a majority of servers. This commit also commits all preceding entries in the leader's log (including entries from former leaders).
- Log matching properties ([[fig:raft_properties]]):
  + if 2 entries in different logs have the same index and term, they store the same command
  + if 2 entries in different logs have the same index and term, then the logs are identical in all preceding entries
- The leader maintain a nextIndex for each follower so he knows which entry it will send
- Election restriction:
  + prevents candidate from winning an election unless its log contains all committed entries
  + a follower denies a candidate vote if its own log is more up-to-date
    - if the logs have last entries with different terms, the log with the later term is more u-t-d
    - if the logs have the same terms as last entries, whichever log is longer is more u-t-d
- Raft handles followers failure by retrying indefinitely the RPCs.
  + RPCs are idempotent; a request that includes log entries already present is ignored
- Timing is crucial only for leader election
  + timing requirement: broadcastTime << electionTimeout << MTBF (average time between failures for a single server)
    - electionTimeout is the only thing chosen : usually, between 10 and 500ms
- Configuration changes comes with two phases
  + joint consensus :: combines both configurations
    - log entries are replicated to all servers in both configurations
    - any server from either configuration can be a leader
    - agreement requires separate majorities from *both* the old and new configurations
    - allows the service of clients even when configuration changes
    - leader log entry for joint consensus C_{old,new} and replicates it
    - servers only uses the latest configuration in its log, whether the entry is committed or not
    - if a leader crash (using the C_{old,new} rules), the new leader may be chosen under C_{old} or C_{old,new} (C_{new} cannot make unilateral decisions during this period)
  + once C_{old,new} has been committed, neither old nor new can make decisions without receiving approval from the other
    - only servers with the C_{old,new} entry can be leader
    - this leader create a log entry for Cnew and replicates it
  + when the new configuration has been commited, servers not in the new configuration can be shut down
  + there are no time when C_{old} or C_{new} can make unilateral decisions
  + when new servers are added, they are non-voting members (not counted for majority)
    - when they have the correct replicated log, the reconfiguration can begin
  + if the leader is not part of the new configuration, it will become follower has soon as he committed C_{new}, and will not count for votes
  + to prevent removed servers from disrupting with votes, the followers disregards the RequestVote RPC

#+CAPTION: A -not-so- condensed summary of the Raft consensus algorithm
#+NAME: fig:raft_conso_algo
[[images/Raft_conso_algo.pdf]]


#+CAPTION: Raft ensured properties
#+NAME: fig:raft_properties
[[images/Raft_properties.png]]


- Clients and log compaction can be found in the [[https://ramcloud.stanford.edu/raft.pdf][extended version of the paper]].

***** Raft evaluation

- Raft implementation contains ~2000 lines of C++ code
- available on [[http://github.com/logcabin/logcabin][Github]]
- easy to understand
- correctness uses [[fig:raft_conso_algo]] and proven in [[https://ramcloud.stanford.edu/~ongaro/thesis.pdf][proof of the State Machine Safety property]]
- performance similar to other consensus algorithms
- recommands using a conservative election timeout such as 150-300ms

***** Related work

- Lamport description of Paxos
- Elaborations of Paxos
- Systems that implement consensus algorithms (Chubby, Zookeeper and Spanner)
- Performance optimizations that can be applied to Paxos
- Viewstamped Replication from Oki and Liskov

***** Conclusion

- Better foundation for system building

*** To go further

- [[http://thesecretlivesofdata.com/raft/][Animated explanation about Raft]]
  + Nothing really new but could be a good starting point if I have to explain Raft
- [[https://www.youtube.com/watch?v=YbZ3zDzDnrw&index=9&list=WL][Raft lecture video]]


** Wednesday 17 January [2018-01-17 mer.]

*** Working on performance tests

- 2 starting points:
  + [[https://docs.openstack.org/performance-docs/latest/test_plans/keystone/plan.html][Keystone Performance testing]]
  + [[https://docs.openstack.org/performance-docs/latest/test_plans/db/plan.html][SQL Database Test plan]]

**** Keystone

- uses Keystone (obviously), OSprofiler and Ceilometer
  + I suspect we will use Enos so we won't have to use Ceilometer

- Test environment

- 2 types of installations:
 - single (all-in-one) installation
   + both controller and computer
 - multi-node installation
   + 4 nodes:
     - 1 compute node simulates typical OS typical activity
     - 3 controller nodes simulate activity typical for OS control plane services
       + includes 3 instances of MySQL managed by Galera cluster and memcached cluster for Keystone caching

- Preparation
  + OSprofiler library is installed on all environment nodes
     - ensure every services needed supports OSprofiler
  + needs Ceilometer for persistent profiling events storage
  + OS services must be configured to allow cross-project request profiling
    - managed on single-node by OSprofiler plugin
    - on multi-node this need to be tracked separately
  + the test cases compare the effectiveness of the use of Keystone database and cache operations
    - requires Keystone reconfiguration depending on whether the cache mechanism is used (cf cache section of keystone.conf)

#+BEGIN_EXAMPLE
[cache]
enabled = True|False
backend = oslo_cache.memcache_pool
memcache_servers = <memcached_host>:<memcached_port>[,<memcached_host>:<memcached_port>]
expiration_time = 600
#+END_EXAMPLE

***** Single node installation

- use DevStack targeted at developers and CI systems, their conf looked like this:
#+BEGIN_EXAMPLE
[[local|localrc]]
ADMIN_PASSWORD=password
DATABASE_PASSWORD=$ADMIN_PASSWORD
RABBIT_PASSWORD=$ADMIN_PASSWORD
SERVICE_PASSWORD=$ADMIN_PASSWORD

LIBS_FROM_GIT=osprofiler,python-openstackclient

NOVA_REPO=https://review.openstack.org/p/openstack/nova
NOVA_BRANCH=refs/changes/03/254703/39

KEYSTONE_REPO=https://review.openstack.org/p/openstack/keystone
KEYSTONE_BRANCH=refs/changes/35/294535/2

NEUTRON_REPO=https://review.openstack.org/p/openstack/neutron
NEUTRON_BRANCH=refs/changes/51/273951/12

disable_service n-net horizon
enable_service q-svc q-dhcp q-meta q-agt q-l3 neutron

enable_plugin ceilometer https://git.openstack.org/openstack/ceilometer.git
enable_plugin osprofiler https://github.com/openstack/osprofiler.git
#+END_EXAMPLE
- add Fernet tokens usage (Symmetric key encryption) if default token format is still UUID
#+BEGIN_EXAMPLE
KEYSTONE_TOKEN_FORMAT=fernet
#+END_EXAMPLE
- have to have identical cache configuration for Keystone authtoken middleware
  + if cache is external (memcached):
#+BEGIN_EXAMPLE
[keystone_authtoken]
memcache_servers = <memcached_host>:<memcached_port>[,<memcached_host>:<memcached_port>]
signing_dir = <signing_dir>
cafile = <cafile.pem>
auth_uri = <auth_uri>
project_domain_id = <domain>
project_name = <service>
user_domain_id = <domain>
password = <password>
username = <project_user_name>
auth_url = <auth_url>
auth_plugin = <password>
#+END_EXAMPLE

***** Multi node installation

- depends of the chosen OS deployment tool
- OSprofiler, Nova, Neutron and Keystone might have to be patched (links in the plan if necessary)
- enable Ceilometer in the ~event_definitions.yaml~
#+BEGIN_EXAMPLE
- event_type: profiler.*
  traits:
    project:
      fields: payload.project
    service:
      fields: payload.service
    name:
      fields: payload.name
    base_id:
      fields: payload.base_id
    trace_id:
      fields: payload.trace_id
    parent_id:
      fields: payload.parent_id
    timestamp:
      fields: payload.timestamp
    host:
      fields: payload.info.host
    path:
      fields: payload.info.request.path
    query:
      fields: payload.info.request.query
    method:
      fields: payload.info.request.method
    scheme:
      fields: payload.info.request.scheme
    db.statement:
      fields: payload.info.db.statement
    db.params:
      fields: payload.info.db.params
#+END_EXAMPLE
- and for extended tracing informations in the ~ceilometer.conf~
#+BEGIN_EXAMPLE
[event]
store_raw=info
#+END_EXAMPLE
- *beware* either turn off not needed events in the .yaml file or save enough room for the Ceilometer backend storage because every info level event will be stored
- for every service, in their .conf file
#+BEGIN_EXAMPLE
[profiler]
enabled = True
trace_sqlalchemy = True
hmac_keys = SECRET_KEY
#+END_EXAMPLE
- they turned profiling on for Cinder, Glance, Nova, Neutron and Keystone.

***** Test Case 1: Keystone DB / cache operations analysis

- records all HTTP, RPC and DB calls in selected control plane operations
  + includes Keystone operations and their duration (via OSprofiler)
- focused of these control plane operations:
  + Keystone token get (token issue)
  + Keystone user list
  + Keystone endpoint list
  + Keystone service list
  + Nova instance boot (server create)
#+BEGIN_EXAMPLE
openstack --profile SECRET_KEY token issue
openstack --profile SECRET_KEY user list
openstack --profile SECRET_KEY endpoint list
openstack --profile SECRET_KEY service list
openstack --profile SECRET_KEY server create --image <image_id> --flavor <flavor_id> <server_name>
#+END_EXAMPLE
- to initiate OS request tracing =profile <HMAC_KEY>= option needs to be added to the CLI command
  + the key is one of the secret keys define in the .conf
  + tracing of the creation of a VM
#+BEGIN_EXAMPLE
openstack --profile SECRET_KEY server create --image <image> --flavor <flavor> <server-name>
#+END_EXAMPLE
  + at the end of the output, there is a message ~osprofiler trace show...~ to know how to get the trace

- parameters

|-----------------------------+----------------------------------------------------|
| Parameter name              | Value                                              |
|-----------------------------+----------------------------------------------------|
| OpenStack release           | Liberty, Mitaka                                    |
| Cache                       | on, off                                            |
| Token type                  | UUID, fernet                                       |
| Environment characteristics | single node, multi-node (clusterized DB/memcached) |
|-----------------------------+----------------------------------------------------|

- performance metrics
|----------+----------------+-------------------+-------------------------------------------|
| Priority | Value          | Measurement Units | Description                               |
|----------+----------------+-------------------+-------------------------------------------|
|        1 | Operation time | milliseconds      | Time spent on every HTTP/RPC/DB operation |
|----------+----------------+-------------------+-------------------------------------------|

- *beware* OSProfiler wrapper includes time spent on Python operations inside methods. For DB calls tracing OSprofiler uses =before/after_cursor_execute=

***** Test Case 2: Keystone DB / cache operations analysis (HA version)

- adds failover testing component
  + first test run is the same as test case 1
  + second needs to happen after turning off one of the distributed components used by Keystone (example: stop one of memcached instances)

- parameters
|-----------------------------+----------------------------------------------------|
| Parameter name              | Value                                              |
|-----------------------------+----------------------------------------------------|
| OpenStack realease          | Pike                                               |
| Cache                       | on, off                                            |
| Token type                  | UUID, fernet                                       |
| Environment characteristics | single node, multi-node (clusterized DB/memcached) |
| Memcached cluster status    | 3 nodes, 2 nodes, 1 node                           |
| Galera cluster status       | 3 nodes, 2 nodes, 1 node                           |
|-----------------------------+----------------------------------------------------|

- performance metrics
|----------+----------------+-------------------+-------------------------------------------|
| Priority | Value          | Measurement Units | Description                               |
|----------+----------------+-------------------+-------------------------------------------|
|        1 | Operation time | milliseconds      | Time spent on every HTTP/RPC/DB operation |
|----------+----------------+-------------------+-------------------------------------------|



**** SQL Database Test Plan

- what are the best pratices for scale and performance of SQL database deployments in OS while maintaining avaibility or all ACID properties?
- only MySQL and variants
- testing done in isolation from other OS components
- Two parts on this plan:
  1. use sysbench to drive simple queries
  2. real db extracted from a deployed production OS and a set of corresponding queries
     + the queries can be played on the same db with various configurations

- Test environment
  + Cluster of 3 hosts for db tests with replication
  + Tests w/o replication use only 1 of these servers
  + 1 additional client machine
  + Hardware is full documented (processor model and frequency, memory size, storage type and capacity, networking interfaces, etc.)

***** Preparation

- On all 3 DB server hosts (details in the report)
  + MySQL installation
  + MariaDB installation
  + Percona Cluster installation
  + Parameters defined in ~/etc/mysql/my.cnf~
  + Permissions defined for database user
- Description of the environment:
  + hardware, as stated above
  + software
    - which ubuntu
    - =ssh_config=
    - "recent" versions of MySQL, MariaDB, Percona, sysbench (keeping in mind that they use Ubuntu 14.04)
  + sysbench description on 3 hosts
    - examples of sysbench commands used for preparation and run

***** Test case 1: sysbench

- Parameters

|-------------------+-------------------------------|
| Parameter         | Value                         |
|-------------------+-------------------------------|
| Database          | MySQL, MariaDB, Percona       |
| Number of threads | 20, 40, 60, 80, 120, 160, 200 |
| Replication       | 1, 3                          |
|-------------------+-------------------------------|

- Database configurations
  + MySQL/InnoDB with Galera
  + MariaDB/XtraDB with Galera
  + MariaDB/InnoDB with Galera
  + Percona Cluster/XtraDB with Galera
  + MySQL with NDB
  + PostgreSQL

- Performance metrics

|----------+-------------+-------------------+----------------------------------------|
| Priority | Value       | Measurement units | Description                            |
|----------+-------------+-------------------+----------------------------------------|
|        1 | throughput  | tps               | transactions/sec, measured by the tool |
|        1 | query lat   | millisec          | query latency, measured by MySQL       |
|        2 | CPU util    | percent           | Average CPU utilization on db server   |
|        2 | Rx BW       | MB/sec            | Average Network receive bandwidth      |
|        2 | Tx BW       | MB/sec            | Average Network transmit bandwidth     |
|        2 | Read BW     | MB/sec            | Average storage read bandwidth         |
|        2 | Write BW    | MB/sec            | Average storage write bandwidth        |
|        2 | Storage lat | millisec          | Average storage latency                |
|----------+-------------+-------------------+----------------------------------------|

***** Test case 2: Database Testing Tool

- goal : quantify query performance with an real OS DB and corresponding queries to develop a portable tool to test DB.
- uses a backup from Mirantis' 200-node cluster and the corresponding queries, imported in different db
- ultimate goal:
  + which software is best for OpenStack
  + how to best configure database parameters
  + which OpenStack queries consume the most resources and are therefore the best candidates for optimization
- parameters
|-------------------+-------------------------------|
| Parameter         | Value                         |
|-------------------+-------------------------------|
| Database          | MySQL, MariaDB, Percona       |
| Number of threads | 20, 40, 60, 80, 120, 160, 200 |
| Replication       | 1, 3                          |
|-------------------+-------------------------------|

- performance metrics
|----------+-------------+-------------------+----------------------------------------|
| Priority | Value       | Measurement Units | Description                            |
|----------+-------------+-------------------+----------------------------------------|
|        1 | throughput  | tps               | transactions/sec, measured by the tool |
|        1 | query lat   | millisec          | query latency, measured by the tool    |
|        2 | CPU util    | percent           | Average CPU utilization on db server   |
|        2 | Memory util | MB                | Memory used on the server              |
|        2 | Rx BW       | MB/sec            | Average Network receive bandwidth      |
|        2 | Tx BW       | MB/sec            | Average Network transmit bandwidth     |
|        2 | Read BW     | MB/sec            | Average storage read bandwidth         |
|        2 | Write BW    | MB/sec            | Average storage write bandwidth        |
|        2 | Storage lat | millisec          | Average storage latency                |
|----------+-------------+-------------------+----------------------------------------|


**** Our tests

- First proposition
- Goal :: compare Keystone over Cockroach and Keystone over Galera
- parameters

|-----------------------------+-------------------------------|
| Parameter name              | Value                         |
|-----------------------------+-------------------------------|
| OpenStack release           | Pike                          |
| Database                    | MySQL (Galera), CockroachDB   |
| Latency between services    | 1, 10, 100, 1000 ms           |
| Environment characteristics | single node, multi-node       |
| Number of threads           | 20, 40, 60, 80, 120, 160, 200 |
| Replication                 | 1, 3                          |
|-----------------------------+-------------------------------|

- Feels like I have no idea what I'm doing, so I submit the parameters to Ronan
  + He confirms that he's not sure if CockroachDB support threads
    - I found no information regarding multithreading for CockroachDB, so it won't be relevant
  + He also finds that the latencies are not relevant
    - I use [[https://wondernetwork.com/pings/Tokyo][the array he gave me]] to put better value
    - He adds that usually it takes at maximum 400ms to ping the entire world
    - I am not sure whether I should add 500ms or it won't be relevant

|-----------------------------+-------------------------------|
| Parameter name              | Value                         |
|-----------------------------+-------------------------------|
| OpenStack release           | Pike                          |
| Database                    | MySQL (Galera), CockroachDB   |
| Latency between services    | LAN, 10, 25, 100, 250, 500 ms |
| Environment characteristics | single node, multi-node       |
| Replication                 | 1, 3                          |
|-----------------------------+-------------------------------|

*** Readings

**** The hows and whys of a distributed SQL database by Alex Robinson
- history
  - first databases were tightly coupled, required a lot of work to use
  - 70s SQL RDBMS queries really independent from the physical storage used for a single machine
  - 80-90s beginning of object-oriented databases tries but not really worked
    + lacked a standard API like SQL
  - early 2000s custom sharding
    + db grew rapidly \to required sharding
    + w/o cross-shard transactions, really hard to operate
  - 2004s NoSQL gave up the relational model, no transactions, no indexes, manual joins
  - 2010s NewSQL /distributed db
    + easier to let developers deal with lack of performance than the lack of transactions
    + attempt to combine the best of both worlds
- how they are built
  - mostly about spanner and cockroachDB
  - data distribution
    + in SQL
      - all data on one server
      - manually shard data across separate DB instances
    + in NoSQL/NewSQL core assumption that you have to cut your data at some point
      - how do you find a particular piece of data
      - how do you divide the data
    + hashing: easy to locate data, but problem: you can do range scans (don't maintain ordering of the data)
      - used in cassandra by default, dynamoDB(amazon)
      - not used in NewSQL
    + order-preserving: put all your data layed out alphatical order and split up into chunks
      - chunks from A to C, etc. (for example)
      - easy to split, efficient scans of the data (range scan) even if data can be on separate nodes
      - no longer have the deterministic function to find where a key is(require additional indexing to find the data)
      - range index to indicate where a piece of data is, don't change too often
      - have to decide when to split (if too big, slow to move data, if too small, the range-index gets to be huge)
    + data-distribution
      - placement: each range is replicated 3 or more times
      - rebalancing when adding a new node for replication
      - recovery: create new copies of the data to have enough replicants
    + data replication
      - keeping copies in sync
	- cold backups: you don't expect them to be up-to-date
	- primary-secondary replication:
	  + one of the copy is the primary takes all of the writes (sometimes all the reads)
	  + the primary send info to the secondary
	  + asynchronous replication
	    - secondary don't receive instantanously data \to failover would loose recent writes
	  + sync..
	    - extra network delays when you're waiting for the writings to get done
	    - what to do when secondary fails?
	  + failovers are really hard to get right
      - keeping copies in sync in NoSQL db
	+ eventually consistent
	+ different methods to keep data consistent, but usually fail (CRDT eventually converge)
      - keeping copies in sync in NewSQL db
	+ uses distributed consensus protocol
	  - Paxos (really hard)
	  - Raft (available openly)
	+ have an odd number of nodes
	+ commit when a majority of nodes comes to a consensus
	+ speaker explains Raft
	  - during failover of a leader before commiting, the write is abandonned
      - consensus in NewSQL db
	+ run one consensus group *per* range of data
    + transactions
      - ACID transactions (Atomic, Consistent, Isolated, Durable)
      - SQL databases
	+ atomiticity bootstrapped off a lower-level atomic primitive: log writes
	  - all mutations part of a transaction get tagged with a transaction
	+ isolation
	  - R/W locks \to require deadlock detection
	  - MVCC timestamp on each row \to versioning of the row
	    + access to historical data
	    + allow long read only transactions to not block new writes
      - NoSQL db
	+ many systems don't offer transaction at all
      - NewSQL db
	+ support traditional ACID semantics
	+ atomicity bootstrapped off distributed consensus
	+ isolation can be handled similarly to single node SQL db
      - CockroachDB
	+ use MVCC
	+ consensus write with number of transaction
	+ when the key for transaction is still present, it's not committed and so reads won't take this key into account
	+ when write conflict happens (ex: same key two times on the same range)
	   - aborting? requires priority to know which one to abort
	   - restart one ?


*** DONE Attending #openstack-meeting
    CLOSED: [2018-01-17 mer. 17:02]




* Todos
** TODO Experience
#+BEGIN_EXAMPLE
Une expé qui serait cool à faire c'est : Faire varier la latence entre keystone et les autres services, puis voir jusqu'à quelle latence le temps d'exécution du control plane est acceptable
#+END_EXAMPLE

** Readings
*** Watch videos
**** TODO Raft
**** DONE CockroachDB
     CLOSED: [2018-01-17 mer. 14:41]
[[The hows and whys of a distributed SQL database by Alex Robinson]]

* Readings

** Preliminary
- [[https://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf][Spanner: Google’s Globally-Distributed Database]]
- [[https://www.usenix.org/system/files/conference/atc14/atc14-paper-ongaro.pdf][In Search of an Understandable Consensus Algorithm]]
- [[https://github.com/cockroachdb/cockroach/blob/master/docs/design.md][CockroachDB doc]]
- [[https://www.youtube.com/watch?v=6OFeuNy39Qg][The hows and whys of a distributed SQL database]] by Alex Robinson
- [[http://vitess.io/][Vitess site]]
- [[https://beyondtheclouds.github.io/blog/openstack/cockroachdb/2017/12/22/a-poc-of-openstack-keystone-over-cockroachdb.html][BTC blog article about Keystone over CockroachDB]]
- [[https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46103.pdf][Spanner: Becoming a SQL System]]
- [[https://www.organicdesign.co.nz/files/4/48/Scalaris.pdf][Scalaris: Reliable Transactional P2P Key/Value Store]]
- [[https://www.mysql.com/products/cluster/scalability.html][MySQL NDB Cluster: Scalability]]
- [[https://www.cockroachlabs.com/docs/stable/configure-replication-zones.html][Configuring Replication Zone on Cockroach]]

** Others
- [[https://en.wikipedia.org/wiki/Paxos_(computer_science)][Paxos]]
- [[http://cnp.neclab.eu/projects/lightvm/lightvm.pdf][My VM is Lighter (and Safer) than your container]] (section 5.1)


* How to

** Org mode

To add a date not added to agenda:
#+BEGIN_SRC
Ctrl-c !
#+END_SRC
To demote current subtree by one level:
#+BEGIN_SRC
Alt-Shift-Left
#+END_SRC


** Using Rally & Tempest

*** Tempest

To run only keystone tests:
#+BEGIN_SRC
tempest run --regex tempest.api.identity
#+END_SRC


** Using devstack

Since it's not using screen anymore, everything is in systemctl.

To restart a service:
#+BEGIN_SRC
sudo systemctl restart devstack@SERVICE_NAME
#+END_SRC
To know the status of a service:
#+BEGIN_SRC
sudo systemctl status devstack@SERVICE_NAME
#+END_SRC


** Other

Cut pages in pdf (from [[https://askubuntu.com/questions/221962/how-can-i-extract-a-page-range-a-part-of-a-pdf][Ask Ubuntu]]):
#+BEGIN_SRC
pdftk full-pdf.pdf cat 12-15 output outfile_p12-15.pdf
#+END_SRC
