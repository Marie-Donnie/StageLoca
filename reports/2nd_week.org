#+TITLE: Report for : Un intergiciel d’une base de données NewSQL qui considère la localité de l’application cliente -- 2nd week --
#+AUTHOR: Marie Delavergne


* Monday 22 January [2018-01-22 lun.]

- Ronan gave me my assignment:
  - we focus on Keystone for now
    - try and deploy with MySQL on 1 node, then on 5 and then on 25
      - there is a variable in kolla-ansible asking what node to use for the database
	- I can fix it to a name defined in enos (controller = 1 node)
    - then try with cockroachDB

- Reminder
#+CAPTION: Test plan (WIP)
#+NAME: tab:test_plan
:test_plan:
|--------------------------+-----------------------------|
| Parameter name           | Value                       |
|--------------------------+-----------------------------|
| OpenStack release        | Pike                        |
| Database                 | MySQL (Galera), CockroachDB |
| Latency between services | LAN, 10, 50, 100, 300 ms    |
| Cluster size             | 1, 5, 25, 100               |
| Replication              | 1, 3, 5                     |
| Number of clients        | 1 (?)                       |
|--------------------------+-----------------------------|


- Useful links:

  - [[https://enos.readthedocs.io/en/stable/][Enos doc]]
    - to [[https://enos.readthedocs.io/en/stable/customization/index.html#changing-the-topology][change the topology]]
  - [[https://github.com/BeyondTheClouds/enos][Enos repo]]
  - [[https://docs.openstack.org/kolla-ansible/latest/][Kolla-Ansible doc]]
  - [[https://github.com/openstack/kolla-ansible][Kolla-Ansible repo]]
    - all services used are in [[https://github.com/openstack/kolla-ansible/tree/master/ansible/roles][roles]]
    - the [[https://github.com/openstack/kolla-ansible/blob/master/ansible/inventory/multinode][inventory]] defines several variables to be used and overloaded if necessary
      #+BEGIN_SRC ansible
      [mariadb:children]
      control
      #+END_SRC

- First, I jump on a frontend on G5K
- Then, I create a virtualenv to run enos
  #+BEGIN_SRC bash
  mkdir enos-deployment && cd enos-deployment
  virtualenv venv
  source venv/bin/activate
  pip install -U pip
  pip install enos
  #+END_SRC
- Then, to configure
  #+BEGIN_SRC bash
  enos new > reservation.yaml
  emacs reservation.yaml
  #+END_SRC
- Realized I've should have done that on a node, so
#+BEGIN_SRC bash
oarsub -I -l 'walltime=2:00:00'
#+END_SRC
- And on the node
#+BEGIN_SRC bash
source venv/bin/activate
nano reservation.yaml
enos deploy
#+END_SRC
- Encountered an error - and so it begins -
#+BEGIN_EXAMPLE
INFO:root:Running playbook /home/madelavergne/enos-deployment/venv/lib/python2.7/site-packages/enos/ansible/utils.yml with vars:
{'action': 'ping', 'tc_output_dir': '/home/madelavergne/enos-deployment/enos_2018-01-22T10:52:07.654187'}
 [WARNING]: Found variable using reserved name: action


PLAY [Utils] *******************************************************************************************

TASK [Gathering Facts] *********************************************************************************
fatal: [ip-control-node]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: ssh: Could not resolve hostname ip-control-node: Name or service not known\r\n", "unreachable": true}
fatal: [ip-compute-node2]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: ssh: Could not resolve hostname ip-compute-node2: Name or service not known\r\n", "unreachable": true}
fatal: [ip-network-node]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: ssh: Could not resolve hostname ip-network-node: Name or service not known\r\n", "unreachable": true}
fatal: [ip-compute-node1]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: ssh: Could not resolve hostname ip-compute-node1: Name or service not known\r\n", "unreachable": true}
	to retry, use: --limit @/home/madelavergne/enos-deployment/venv/lib/python2.7/site-packages/enos/ansible/utils.retry

PLAY RECAP *********************************************************************************************
ip-compute-node1           : ok=0    changed=0    unreachable=1    failed=0
ip-compute-node2           : ok=0    changed=0    unreachable=1    failed=0
ip-control-node            : ok=0    changed=0    unreachable=1    failed=0
ip-network-node            : ok=0    changed=0    unreachable=1    failed=0

{'code': 4, 'result': [{u'ip-network-node': {'unreachable': 1, 'skipped': 0, 'ok': 0, 'changed': 0, 'failures': 0}}, {u'ip-compute-node1': {'unreachable': 1, 'skipped': 0, 'ok': 0, 'changed': 0, 'failures': 0}}, {u'ip-compute-node2': {'unreachable': 1, 'skipped': 0, 'ok': 0, 'changed': 0, 'failures': 0}}, {u'ip-control-node': {'unreachable': 1, 'skipped': 0, 'ok': 0, 'changed': 0, 'failures': 0}}], 'playbook': '/home/madelavergne/enos-deployment/venv/lib/python2.7/site-packages/enos/ansible/utils.yml'}
ERROR:root:Unreachable hosts: [u'ip-network-node', u'ip-compute-node1', u'ip-compute-node2', u'ip-control-node']
INFO:root:Hosts unreachable: [u'ip-network-node', u'ip-compute-node1', u'ip-compute-node2', u'ip-control-node']
INFO:root:Retrying... 1/100
#+END_EXAMPLE
- Let it retry but no better
- Changed the configuration so it would look like more the one given as an example, still not better
#+BEGIN_EXAMPLE
provider:
  type: g5k
  name: 'Enos'
  walltime: 02:00:00
  env_name: jessie-x64-min
  reservation: None
  vlans: '{rennes: "{type=kavlan}/vlan=1"}'
  role_distribution: strict
  single_interface: false
  user: root
#+END_EXAMPLE

- Been asking to Ronan, he told me to remove everything between G5K conf and inventory in the ~reservation.yaml~, so the right configuration looks like:
#+BEGIN_EXAMPLE
# ############################################### #
# Grid'5000 reservation parameters                #
# ############################################### #
provider:
 type: g5k
 name: 'Enos'
 walltime: '02:00:00'
 env_name: debian9-x64-min
 # mandatory : you need to have exacly one vlan
 vlans:
    rennes: "{type='kavlan'}/vlan=1"
 # Be less strict on node distribution especially
 # when nodes are missing in the reservation
 # or not deployed
 role_distribution: debug

# Resources description
resources:
 paravance:
   control: 1
   compute: 1
   database: 1

# ############################################### #
# Inventory to use                                #
# ############################################### #

# This will describe the topology of your services
inventory: inventory-mariadb-out.ini

# ############################################### #
# docker registry parameters
# ############################################### #

# A registry will be deployed and used during the deployment
registry:
 type: internal
 ceph: true
 ceph_keyring: /home/discovery/.ceph/ceph.client.discovery.keyring
 ceph_id: discovery
 ceph_rbd: discovery_kolla_registry/datas
 ceph_mon_host:
   - ceph0.rennes.grid5000.fr
   - ceph1.rennes.grid5000.fr
   - ceph2.rennes.grid5000.fr

# ############################################### #
# Enos Customizations                             #
# ############################################### #
enable_monitoring: no


# ############################################### #
# Kolla parameters                                #
# ############################################### #
# Repository
kolla_repo: "https://git.openstack.org/openstack/kolla-ansible"
kolla_ref: "stable/pike"

# Vars : globals.yml
kolla:
 openstack_release: "osprofiler-stable-pike"
 kolla_base_distro: "centos"
 kolla_install_type: "source"
 docker_namespace: "beyondtheclouds"
 enable_heat: "no"
#+END_EXAMPLE

- I can check in inventories used how the variables are defined
  - in this example, there is a node for database BUT as we saw
      #+BEGIN_SRC
      [mariadb:children]
      control
      #+END_SRC
  - this tells us that mariadb is used on the control node

- Trying to make bench, but got
#+BEGIN_EXAMPLE
enos bench --workload=workload
Traceback (most recent call last):
 File "/home/madelavergne/enos-deployment/venv/bin/enos", line 11, in <module>
   sys.exit(main())
 File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/enos.py", line 774, in main
   bench(**docopt(bench.__doc__, argv=argv))
 File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/utils/enostask.py", line 77, in decorated
   fn(*args, **kwargs)
 File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/utils/enostask.py", line 100, in decorator
   return fn(*args, **kwargs)
 File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/enos.py", line 360, in bench
   playbook_values = mk_enos_values(env)
 File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/utils/extra.py", line 301, in mk_enos_values
   get_kolla_required_values(env),
 File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/utils/extra.py", line 240, in get_kolla_required_values
   'network_interface':          env['eths'][NETWORK_IFACE],
KeyError: 'eths'
#+END_EXAMPLE

- Realized the deployment didn't work really fine
#+BEGIN_EXAMPLE
INFO:execo:Setting ['paravance-66-eth1.rennes.grid5000.fr', 'paravance-56-eth1.rennes.grid5000.fr', 'paravance-64-eth1.rennes.grid5000.fr'] in vlan 4 of site rennes
Traceback (most recent call last):
 File "/home/madelavergne/enos-deployment/venv/bin/enos", line 11, in <module>
   sys.exit(main())
 File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/enos.py", line 766, in main
   deploy(**docopt(deploy.__doc__, argv=argv))
 File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/utils/enostask.py", line 77, in decorated
   fn(*args, **kwargs)
 File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/enos.py", line 658, in deploy
   up(**kwargs)
 File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/utils/enostask.py", line 77, in decorated
   fn(*args, **kwargs)
 File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/enos.py", line 108, in up
   provider.init(config, kwargs['--force-deploy'])
 File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/provider/g5k.py", line 50, in init
   vlans)
 File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/provider/g5k.py", line 308, in _mount_cluster_nics
   vlan)
 File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/execo_g5k/api_utils.py", line 714, in set_nodes_vlan
   return _get_g5k_api().post('/sites/%s/vlans/%s' % (site, str(vlan_id)), json.dumps({"nodes": network_addresses}))
 File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/execo_g5k/api_utils.py", line 203, in post
   raise APIException(uri, 'POST', response, content)
execo_g5k.api_utils.APIException: <APIException uri=u'https://api.grid5000.fr/3.0/sites/rennes/vlans/4' method=POST response={'status': '401', 'content-length': '463', 'server': 'Apache/2.4.25 (Debian)', 'date': 'Mon, 22 Jan 2018 10:49:05 GMT', 'content-type': 'text/html; charset=iso-8859-1', 'www-authenticate': 'Basic realm="Grid\'5000 API"'} content='<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">\n<html><head>\n<title>401 Unauthorized</title>\n</head><body>\n<h1>Unauthorized</h1>\n<p>This server could not verify that you\nare authorized to access the document\nrequested.  Either you supplied the wrong\ncredentials (e.g., bad password), or your\nbrowser doesn\'t understand how to supply\nthe credentials required.</p>\n<hr>\n<address>Apache/2.4.25 (Debian) Server at api.grid5000.fr Port 443</address>\n</body></html>\n'>
#+END_EXAMPLE


- Using the doc for [[https://enos.readthedocs.io/en/2.3.0/provider/grid5000.html#deployment][2.3]] (thanks to Ronan), I can see that I require to add a file and change the setup on the frontend.

- Seems to run smoothly, something must be wrong somewhere.

- Of course, since I only took 2:00:00, I need to do it all over again after eating.

- Working on the files to enable working on 5 and 25 nodes at the same time
  - Copied inventory.sample, changed
      #+BEGIN_SRC
      [mariadb:children]
      database
      #+END_SRC
  - By doing so, I will use the number of nodes declared in the reservation.yaml file, which I also change to 5 and then 25.

- Launched bench (using ~nova-boot-list-cc.yml~)
  - on rally, you can run a [[https://github.com/openstack/rally/blob/master/tasks/openstack/scenario/keystone.yaml][task]]
    - usage: ~rally task validate task.yaml --task-args-file task_arguments.yaml~
  - but there are also the [[https://github.com/openstack/rally/tree/master/samples/tasks/scenarios/keystone][sample tasks]]
  - didn't work for nova scenario but I tested for one keystone scenario and it seemed it has ran smoothly, so I entirely changed the ~run.yml~ to run every scenarios
  - launched the full ~run.yml~
  - backup the reports from ~enos backup~
  - changed the files as stated above
  - relaunched deployment
    - got a problem with my deployment, it used the oargridjob already used, which hadn't enough nodes
    - don't work with ~oardel~ MUST use ~oargriddel <job_number>~ or ~enos destroy --hard~
    - finally got it working with ~oargriddel~
      #+BEGIN_EXAMPLE
      TASK [mariadb : Creating mariadb volume]
      changed: [paravance-6-kavlan-4.rennes.grid5000.fr]
      changed: [paravance-58-kavlan-4.rennes.grid5000.fr]
      changed: [paravance-61-kavlan-4.rennes.grid5000.fr]
      changed: [paravance-66-kavlan-4.rennes.grid5000.fr]
      changed: [paravance-64-kavlan-4.rennes.grid5000.fr]
      #+END_EXAMPLE
    - \o/... wait
      #+BEGIN_EXAMPLE
FAILED - RETRYING: Waiting for MariaDB service to be ready through VIP (1 retries left).
FAILED - RETRYING: Waiting for MariaDB service to be ready through VIP (1 retries left).
FAILED - RETRYING: Waiting for MariaDB service to be ready through VIP (1 retries left).
FAILED - RETRYING: Waiting for MariaDB service to be ready through VIP (1 retries left).
FAILED - RETRYING: Waiting for MariaDB service to be ready through VIP (1 retries left).
fatal: [paravance-61-kavlan-4.rennes.grid5000.fr]: FAILED! => {"attempts": 6, "changed": false, "cmd": ["docker", "exec", "mariadb", "mysql", "-h", "10.24.61.255", "-P", "3306", "-u", "haproxy", "-e", "show databases;"], "delta": "0:00:03.237623", "end": "2018-01-22 16:50:44.888256", "failed": true, "rc": 1, "start": "2018-01-22 16:50:41.650633", "stderr": "ERROR 2003 (HY000): Can't connect to MySQL server on '10.24.61.255' (113 \"No route to host\")", "stderr_lines": ["ERROR 2003 (HY000): Can't connect to MySQL server on '10.24.61.255' (113 \"No route to host\")"], "stdout": "", "stdout_lines": []}
fatal: [paravance-58-kavlan-4.rennes.grid5000.fr]: FAILED! => {"attempts": 6, "changed": false, "cmd": ["docker", "exec", "mariadb", "mysql", "-h", "10.24.61.255", "-P", "3306", "-u", "haproxy", "-e", "show databases;"], "delta": "0:00:03.210377", "end": "2018-01-22 16:50:44.926697", "failed": true, "rc": 1, "start": "2018-01-22 16:50:41.716320", "stderr": "ERROR 2003 (HY000): Can't connect to MySQL server on '10.24.61.255' (113 \"No route to host\")", "stderr_lines": ["ERROR 2003 (HY000): Can't connect to MySQL server on '10.24.61.255' (113 \"No route to host\")"], "stdout": "", "stdout_lines": []}
fatal: [paravance-64-kavlan-4.rennes.grid5000.fr]: FAILED! => {"attempts": 6, "changed": false, "cmd": ["docker", "exec", "mariadb", "mysql", "-h", "10.24.61.255", "-P", "3306", "-u", "haproxy", "-e", "show databases;"], "delta": "0:00:03.231754", "end": "2018-01-22 16:50:44.927383", "failed": true, "rc": 1, "start": "2018-01-22 16:50:41.695629", "stderr": "ERROR 2003 (HY000): Can't connect to MySQL server on '10.24.61.255' (113 \"No route to host\")", "stderr_lines": ["ERROR 2003 (HY000): Can't connect to MySQL server on '10.24.61.255' (113 \"No route to host\")"], "stdout": "", "stdout_lines": []}
fatal: [paravance-66-kavlan-4.rennes.grid5000.fr]: FAILED! => {"attempts": 6, "changed": false, "cmd": ["docker", "exec", "mariadb", "mysql", "-h", "10.24.61.255", "-P", "3306", "-u", "haproxy", "-e", "show databases;"], "delta": "0:00:03.269421", "end": "2018-01-22 16:50:44.936793", "failed": true, "rc": 1, "start": "2018-01-22 16:50:41.667372", "stderr": "ERROR 2003 (HY000): Can't connect to MySQL server on '10.24.61.255' (113 \"No route to host\")", "stderr_lines": ["ERROR 2003 (HY000): Can't connect to MySQL server on '10.24.61.255' (113 \"No route to host\")"], "stdout": "", "stdout_lines": []}
fatal: [paravance-6-kavlan-4.rennes.grid5000.fr]: FAILED! => {"attempts": 6, "changed": false, "cmd": ["docker", "exec", "mariadb", "mysql", "-h", "10.24.61.255", "-P", "3306", "-u", "haproxy", "-e", "show databases;"], "delta": "0:00:03.256196", "end": "2018-01-22 16:50:45.010870", "failed": true, "rc": 1, "start": "2018-01-22 16:50:41.754674", "stderr": "ERROR 2003 (HY000): Can't connect to MySQL server on '10.24.61.255' (113 \"No route to host\")", "stderr_lines": ["ERROR 2003 (HY000): Can't connect to MySQL server on '10.24.61.255' (113 \"No route to host\")"], "stdout": "", "stdout_lines": []}
	to retry, use: --limit @/home/madelavergne/enos-deployment/enos_2018-01-22T16:29:36.577602/kolla/ansible/site.retry

PLAY RECAP *********************************************************************************************
paravance-51-kavlan-4.rennes.grid5000.fr : ok=9    changed=4    unreachable=0    failed=0
paravance-58-kavlan-4.rennes.grid5000.fr : ok=47   changed=23   unreachable=0    failed=1
paravance-6-kavlan-4.rennes.grid5000.fr : ok=38   changed=20   unreachable=0    failed=1
paravance-61-kavlan-4.rennes.grid5000.fr : ok=38   changed=20   unreachable=0    failed=1
paravance-64-kavlan-4.rennes.grid5000.fr : ok=38   changed=20   unreachable=0    failed=1
paravance-66-kavlan-4.rennes.grid5000.fr : ok=38   changed=20   unreachable=0    failed=1
paravance-68-kavlan-4.rennes.grid5000.fr : ok=3    changed=0    unreachable=0    failed=0
Command failed ansible-playbook -i /home/madelavergne/enos-deployment/enos_2018-01-22T16:29:36.577602/multinode -e @/home/madelavergne/enos-deployment/enos_2018-01-22T16:29:36.577602/globals.yml -e @/home/madelavergne/enos-deployment/enos_2018-01-22T16:29:36.577602/passwords.yml -e CONFIG_DIR=/home/madelavergne/enos-deployment/enos_2018-01-22T16:29:36.577602  -e action=deploy /home/madelavergne/enos-deployment/enos_2018-01-22T16:29:36.577602/kolla/ansible/site.yml
Traceback (most recent call last):
  File "/home/madelavergne/enos-deployment/venv/bin/enos", line 11, in <module>
    sys.exit(main())
  File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/enos.py", line 766, in main
    deploy(**docopt(deploy.__doc__, argv=argv))
  File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/utils/enostask.py", line 77, in decorated
    fn(*args, **kwargs)
  File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/enos.py", line 665, in deploy
    install_os(**kwargs)
  File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/utils/enostask.py", line 77, in decorated
    fn(*args, **kwargs)
  File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/utils/enostask.py", line 100, in decorator
    return fn(*args, **kwargs)
  File "/home/madelavergne/enos-deployment/venv/local/lib/python2.7/site-packages/enos/enos.py", line 207, in install_os
    check_call(kolla_cmd)
  File "/usr/lib/python2.7/subprocess.py", line 186, in check_call
    raise CalledProcessError(retcode, cmd)
subprocess.CalledProcessError: Command '['/home/madelavergne/enos-deployment/enos_2018-01-22T16:29:36.577602/kolla/tools/kolla-ansible', 'deploy', '-i', '/home/madelavergne/enos-deployment/enos_2018-01-22T16:29:36.577602/multinode', '--passwords', '/home/madelavergne/enos-deployment/enos_2018-01-22T16:29:36.577602/passwords.yml', '--configdir', '/home/madelavergne/enos-deployment/enos_2018-01-22T16:29:36.577602']' returned non-zero exit status 1
      #+END_EXAMPLE
    - nooo *insert here a gif of darth vader*
    - checked the gantt diagram for [[https://intranet.grid5000.fr/oar/Rennes/drawgantt-svg/][Rennes]], I still have those nodes
    - relaunched ~enos deploy~
    - same shit
    - try to redeploy, just in case
    - still stuck at =TASK [mariadb : Waiting for MariaDB service to be ready through VIP]=
    - searched a bit for this error on the net. Seems there was a bug with ports 2 years back, but it's supposed to be fixed and I can't find much about this error if filtering only this year.


- While waiting for the tests to run, I'm trying to do minor changes to my enos
  - Corrected a typo
  - Create different reservation.yaml.sample for different providers (in my case, g5k)
    - Wondering about the usefulness of this...
    - usage: ~enos new grid5000 > reservation.yaml~
    - would require to make a new sample and modify ~enos.py~ each time a provider is added


- Since 5 nodes for the db doesn't work at that time, I will try to make cockroach work with enos
  - I revert my changes to ~reservation.yaml~

- Ronan came to help me

  - look for tuto galera/mariadb docker
  - cf notes


* Tuesday 23 January [2018-01-23 mar.]

** Beginning work on enoslib

- [[https://github.com/BeyondTheClouds/enoslib][EnOSlib]]
- [[https://enoslib.readthedocs.io/en/latest/][EnOSlib doc]]

- Enoslib allows to get resources from a testbed and deploy an experiment workflow on those resources
  - does not only deploy OS
- So I will have to:
  1. get the resources
  2. deploy MariaDB+Galera / CockroachDB
     - will have to be containerized
  3. deploy OS with devstack


- First of all, I clone enoslib.
- Doing the tutorial for grid5k \to ok
- Trying to understand how [[https://github.com/msimonin/ombt-orchestrator][ombt orchestrator]] is working
  - Following the readme, add to adapt it a bit, because there was no
    #+BEGIN_SRC
git clone https://github.com/msimonin/qpid-dispatch-xp
cd qpid-dispatch-xp
    #+END_SRC
    - Could have used =git clone https://github.com/msimonin/ombt-orchestrator.git=
  - Tried to see the usage
    #+BEGIN_EXAMPLE
    (venv) madelavergne@frennes:~/qpid-dispatch-xp$ ./cli.py
No handlers could be found for logger "vagrant"
Usage: cli.py [OPTIONS] COMMAND [ARGS]...

Options:
  --help  Show this message and exit.

Commands:
  backup       Backup the environment
  campaign
  deploy       Claim resources from a provider and configure...
  destroy      Destroy all the running dockers (not...
  g5k          Claim resources on Grid'5000 (from a...
  inventory    Generate the Ansible inventory file.
  prepare      Configure the resources.[after g5k,vagrant...
  test_case_1  Runs the test case 1 : one single large...
  vagrant      Claim resources on vagrant (local machine)
    #+END_EXAMPLE

  - I'm probably going to need g5k option, there are no confs folder anyway
    #+BEGIN_EXAMPLE
(venv) madelavergne@frennes:~/qpid-dispatch-xp$ ./cli.py g5k
No handlers could be found for logger "vagrant"
INFO:root:Generate results directory /home/madelavergne/qpid-dispatch-xp/enos_2018-01-23T10:32:49.966966
INFO:root:Symlink /home/madelavergne/qpid-dispatch-xp/enos_2018-01-23T10:32:49.966966 to current
INFO:root:- Task g5k started -
Traceback (most recent call last):
  File "./cli.py", line 223, in <module>
    cli()
  File "/home/madelavergne/qpid-dispatch-xp/venv/local/lib/python2.7/site-packages/click/core.py", line 722, in __call__
    return self.main(*args, **kwargs)
  File "/home/madelavergne/qpid-dispatch-xp/venv/local/lib/python2.7/site-packages/click/core.py", line 697, in main
    rv = self.invoke(ctx)
  File "/home/madelavergne/qpid-dispatch-xp/venv/local/lib/python2.7/site-packages/click/core.py", line 1066, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/home/madelavergne/qpid-dispatch-xp/venv/local/lib/python2.7/site-packages/click/core.py", line 895, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/madelavergne/qpid-dispatch-xp/venv/local/lib/python2.7/site-packages/click/core.py", line 535, in invoke
    return callback(*args, **kwargs)
  File "./cli.py", line 53, in g5k
    t.g5k(force)
  File "/home/madelavergne/qpid-dispatch-xp/venv/local/lib/python2.7/site-packages/enoslib/task.py", line 50, in decorated
    fn(*args, **kwargs)
TypeError: g5k() got multiple values for keyword argument 'env'
    #+END_EXAMPLE

  - In the examples, he uses deploy with vagrant, so
    #+BEGIN_EXAMPLE
(venv) madelavergne@frennes:~/qpid-dispatch-xp$ ./cli.py deploy --provider=g5k
No handlers could be found for logger "vagrant"
Usage: cli.py deploy [OPTIONS] BROKER

Error: Missing argument "broker".
    #+END_EXAMPLE

  - As in the examples, I add rabbitmq as the broker
    #+BEGIN_EXAMPLE
(venv) madelavergne@frennes:~/qpid-dispatch-xp$ ./cli.py deploy --provider=g5k rabbitmq
    #+END_EXAMPLE

  - it began its work, deploying on 4 parasilo nodes
  - when it is done, I try to launch the same benchmark Matthieu used
    #+BEGIN_SRC
    ./cli.py test_case_1 --nbr_clients 10 --nbr_servers 2
    #+END_SRC
  - do the backup, it is just like enos
    #+BEGIN_SRC
    ./cli.py backup
    #+END_SRC
  - then destroy
    #+BEGIN_SRC
    ./cli.py destroy
    #+END_SRC

- Since the test was done with ~test_case_1.ipynb~, I feel like I have to check how one can use Jupyter, as Ronan told me that was Matthieu uses for ombt-orchestration
  - [[Https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html][Jupyter doc]]


** Formalism on distributed databases

- Adrien had a question about why we don't just forward the request as seen on

#+CAPTION: Dynamic table union
#+NAME: fig:forma_request
[[../images/Forma_request.png]]

- A is the federation  of databases.
- B, C and D are concrete databases who share, as an example, all Openstack tables
- A receives a request requiring to use B, C and D
- a lock would be used on each rows required

- what we want is to be able to make requests on a federation (union) of databases that share the same schema

- For that, we will probably need
  + projection: unary operation defining a subset of a relation
    - noted \Pi_{a_1,...,a_n}(R)
    - with:
      + a_{1},...,a_{n}: set of attribute names
      + R: the relation from which the subset will be taken
    - result:
      + \Pi_{a_1, ...,a_n}(R) = {t[a_{1}..,a_n}] : t \in R}
      + with t[a_{1},...,a_{n}] = { (a', v) | (a', v) \in t, a' \in a_{1},..,a_{n}
    - example:
      + \Pi_{age,weight}(Person): age and weight are the attribute names, Person is the relation
    - in SQL: ~SELECT~
  + selection: unary operation defining a subset of a relation too
    - noted \sigma_{a \theta b}(R) or \sigma_{a \theta v}(R)
    - with:
      + a and b: attribute names
      + \theta: binary operation in the set { \lt, \leq, =, \neq, \geq, \gt }
      + v: constant value
      + R: relation from which the subset will be taken
     - result:
      + \sigma_{a \theta b}(R) = { t : t \in R, t(a) \theta t(b)}
      + \sigma_{a \theta v}(R) = { t : t \in R, t(a) \theta v}
    - example:
      + \sigma_{age=34}(Person): age is the attribute name, 34 a constant value and Person the relation
      + \sigma_{age=weight}(Person): age and weight are attributes names and Person the relation
    - in SQL: ~WHERE~
  + (set) union
    - noted R_{1} \cup R_{2} = {x: x \in R_{1} \vee x \in R_{2}}
  + (set) difference
    - noted R_{1} \ R_{2} = {x: x \in R_{1} \wedge x \notin R_{2}}
  + intersection
    - noted R_{1} \cap R_{2} = {x: x \in R_{1} \wedge x \in R_{2}}
  + Cartesian product
    - noted R_{1} \times R_{2} = {(x,y): x \in R_{1} \wedge y \in R_{2}}
    - in SQL: ~CROSS JOIN~
  + natural join
    - noted R \bowtie S = { r \cup s | r \in R \wedge s \in S \wedge P(r \cup s)}
    - with P a predicate that is true for a function t.
    - note: if R and S have no common attribute, it's the cartesian product
    - in SQL: ~NATURAL JOIN~

- Now we will have to use them on our operations, i.e. (from Ronan):
  - a. Create Role/Project
  - b. Create/Register a service end-point
  - c. Create a VMI
  - d. Create a Network for the VM
  - e. Create a VM on the ''orginal'' site
  - f. Create/use a remote-attached volume (cinder like capability)

- To do so, I'm reading chapter 7 from /Principles of Distributed Database Systems/
  + they present the transformations (equivalence) rules described by Ullman
    1. commutativity of binary operators ( A R B \Leftrightarrow B R A)
       - cartesian product
       - join
       - union
    2. associativity of binary operators ( A R(B R C) \Leftrightarrow (A R B)R C
       - cartesian product
       - join
    3. idempotence of unary operators ( R(R(A)) \Leftrightarrow R(A) )
       - projection: \Pi_{A'}(\Pi_{A''}(R) \Leftrightarrow \Pi_{A'}(R)
       - selection: \sigma_{p_1(A_1)}(\sigma_{p_2(A_2)}(R)) = \sigma_{p_1(A_1) \wedge p_2(A_2)}(R)
    4. Commuting selection with projection
       - \Pi_{A_1,...,A_n}(\sigma_{p(A_p)}(R)) \Leftrightarrow \Pi_{A_1,...,A_n}(\sigma_{p(A_p)}(\Pi_{A_1,...,A_n,A_p}(R)))
    5. Commuting selection with binary operators
    6. Commuting projection with binary operators
  + the techniques for decomposing and restructuring queries apply to both centralized and distributed DBMS
    - do not take into account the distribution of data
    - this is the role of the localization layer
      #+CAPTION: Normalized relations used in the book
      #+NAME: fig:normalized_relations
      [[../images/PDDS_normalized_relations.png]]
    - when fragmenting a relation *horizontally*, the localization program needs the union of the fragments
      + selection: when fragments are selected by contradicting predicates (i.e. none of the tuples from the tables can satisfy the predicate of other tables), a selection can be reduced using these predicates
      #+CAPTION: Reduction for Horizontal Fragmentation (with Selection)
      #+NAME: fig:reducing_selection
      [[../images/PDDS_reduc_selec.png]]
      + join: when fragments from different relations have an equivalent predicate, you use the union of joins from the corresponding fragments rather than the join of unions if the partial joins are few in numbers
	- localized query better when there are a large number of partial joins in the reduced query
	- and so reduced query is better when the number of partial joins is small
      #+CAPTION: Reduction for Horizontal Fragmentation (with Join)
      #+NAME: fig:reducing_join
      [[../images/PDDS_reduc_join.png]]

*** Sources

- [[https://en.wikipedia.org/wiki/Relational_algebra][relational algebra]] on Wikipedia
- Principles of Distributed Database Systems by M. Tamer Özsu, Patrick Valduriez
- Principles of Database Systems by Jeffrey D. Ullman


* Wednesday 24 January [2018-01-24 mer.]

- Resumed reading Principles of Distributed Database Systems

** Readings

- Reminder for fragmentation (partitioning):
  + horizontal partitioning, also called sharding, consists in separating different rows into different tables, based on a value of an attribute
  + vertical partitioning separates the tables on their columns
  + hybrid partitioning uses both kind of fragmentations, producing a tree-sructured partitioning (horizontal then vertical or vice versa)
  + derived horizontal partitioning defined on a member relation of a link according to a selection specified on its owner
- when fragmenting a relation *vertically*, the localization program needs the join of the fragments
  + projection: when doing a projection on attributes, you can reduce the query to the fragments that actually have that column
    #+CAPTION: Reduction for Vertical Fragmentation
    #+NAME: fig:reducing_projection
    [[../images/PDDS_reduc_projec.png]]
  + for distributed fragmentation, you have to reduce the query by removing the useless branches
    #+CAPTION: Reduction for Derived Fragmentation
    #+NAME: fig:reducing_derived
    [[../images/PDDS_reduc_distributed_frag.png]]
    - the query was
      #+BEGIN_SRC sql
SELECT *
FROM EMP, ASG
WHERE ASG.ENO = EMP.ENO
AND TITLE = "Mech. Eng."
      #+END_SRC
    - the corresponding localized query is shown in figure (a), with
      + ASG_{1} = ASG |X_{ENO} EMP_{1}
      + ASG_{2} = ASG |X_{ENO} EMP_{2}
      + EMP_{1} = \sigma_{TITLE=”Programmer”}(EMP)
      + EMP_{2} = σ_{TITLE \neq ”Programmer”}(EMP)
    - (b) Since the selection for Title="Mech. Eng." conflicts with EMP_{1} (Title="Programmer"), we can remove EMP_{1}
    - (c) Using (R_{1} \cup R_{2} ) |X| S = (R_{1} |X| S) \cup (R_{2} |X| S), the unions are pushed up
    - (d) On the left branch, there can be no join on Title="Programmer" and Title\neq"Programmer", so the branch is removed
  + for hybrid, you can combine the rules used in horizontal, vertical and derived horizontal fragmentation:
    1. Remove empty relations generated by contradicting selections on horizontal fragments
    2. Remove useless relations generated by projections on vertical fragments
    3. Distribute joins over unions in order to isolate and remove useless joins

- Queries produced by decomposition and data localization layers
  + produce a query where worse executions are avoided
  + can be optimized further using quantitative information on the fragments

- Looking the chapter 6, which seems interesting because query processing is interesting in our case (cf notes)

#+CAPTION: Complexity of Relational Algebra Operations (with n: relation cardinality)
#+NAME: tab:complexity_RA_operations
|-----------------------------------------+------------+--------|
| Operation                               | Complexity | Type   |
|-----------------------------------------+------------+--------|
| Select                                  | O(n)       | Unary  |
| Project (without duplicate elimination) |            |        |
|-----------------------------------------+------------+--------|
| Project (with duplicate elimination)    | O(n*log n) | Unary  |
| Group by                                |            |        |
|-----------------------------------------+------------+--------|
| Join                                    |            | Binary |
| Semi-join                               | O(n*log n) |        |
| Division                                |            |        |
| Set Operators                           |            |        |
|-----------------------------------------+------------+--------|
| Cartesian Product                       | O(n^{2})      | Binary |
|-----------------------------------------+------------+--------|

- Two principles comes from this table:
  + since complexity is relative to relation cardinalities, selections should be performed first as they reduce the cardinality
  + operators should be ordered by increasing complexity to avoid or delay costly operators like Cartesian Product
- Import characteristics of query processors (the last four are particular to distributed query processors in tightly integrated distributed DBMS:
  + language
    - query processing must perform efficient mapping between the input and the output languages
  + types of optimization
    - important but costly, especially when the number of relations or fragments involved increases
    - use of heuristics
      + minimize the size of intermediate relations; it is done by performing unary operators first and then ordering the binary ones by the increasing size of their intermediate
      + in DS: replace join operators by combinations of semijoins to minimize data communication
  + optimization timing
    - optimizations can be done statically before executing the query, or dynamically as the query is executed
  + statistics
    - need periodic updating
    - help improving a query optimization
  + decision sites
    - decision process can be centralized (requires knowledge of the entire DDb), distributed (requires only local information) or hybrid (one site make the major decisions and others make local decisions)
  + exploitation of the network topology
    - LAN: optimization of the processing of join operators
    - other algorithms specialize on star networks or sattelite networks
    - for a client-server environment, the client can be exploited to perform database operators
  + eploitation of replicated fragments
    - some algorithms exploits the replicated fragments at run time to minimize the cost of communication
  + use of semijoins
    - reduce the size of operand relation

- Static and semicentralized query processor
#+CAPTION: Generic Layering Scheme for Distributed Query Processing
#+NAME: fig:layer_qp
[[../images/PDDS_layers_qp.png]]
- Query decomposition:
  1. Normalization of the query by rewrittings. It usually involves the manipulation of query quantifiers and qualification by applying logical operator priority
  2. Semantic analysis of the query to seek and reject incorrect queries
  3. Simplification of the query (elimination of redundancy)
  4. Restructuration of the query into an algebraic query


- Reading a bit of Chapter 3, 10, 11, 12.6, 13, 18.2.4


** Meeting with Ronan

- He precised a bit what was expected:
  - Make OS like routers that knows their neighboors and forward the requests if necessary where it will be needed
  - Will be needing a [[https://en.wikipedia.org/wiki/Federated_database_system][federated database system]] probably
  - It will be up to the databases to know when to forward the request
    - need to consider locality: your data will be on the OS you use, but you might need some data on another OS
    - if the OS (database) you needed isn't available, just like a website, well it's not really important because you can't do anything with it anyway (e.g. you can't start a VM on it)
      - what if your VM info was on another OS (if your OS deemed that you required to start the VM elsewhere)?
    - the database on "your" OS will manage its own database and the replicates from others
- I should ask Ronan if this is what he meant
- Tomorrow I will be able to resume my work on the tests


* Thursday 25 January [2018-01-25 jeu.]

- Resumed work on ombt/tests

** Tests

[[tab:test_plan]]

- Getting the conf.yaml right
  + To do so, I'm looking how a role is defined \to ~ansible/roles/ROLE/tasks/~
    - it seems that there are always:
      + ~backup.yml~
	- how to get the logs when you do a backup
      + ~deploy.yml~
	- defines how the role/service is deployed (e.g. installation/configuration/restart)
      + ~destroy.yml~
	- removes the data and container (usually)
      + ~main.yml~
	- includes ={{enos_action}}.yml=
  + I'm going to fork the project since I will change to many things
  + I have to check how to use MariaDB/Galera with docker
    - [[https://blog.pythian.com/building-a-mariadb-galera-cluster-with-docker/][one tutorial]]
      - not sure if it's ok, I'm going to ask Ronan what I really need
      - Ronan gave me the link to [[https://www.cockroachlabs.com/docs/stable/start-a-local-cluster-in-docker.html#os-linux][start a local cluster in docker (CockroachDB)]] and a lesson he did about Docker

- I do the tutorial to start a local cluster in docker for CockroachDB

#+CAPTION: Generic Layering Scheme for Distributed Query Processing
#+NAME: fig:layer_qp
[[../images/Docker_tuto_local_cluster.png]]

- I won't be needing the [[https://www.cockroachlabs.com/docs/stable/orchestrate-cockroachdb-with-docker-swarm.html][tutorial to orchestrate cockroachdb with docker swarm]] since we are not doing a production deployment
  - so I just need to be able to reproduce the tutorial for each nodes (one cockroachdb/node)

- While I'm thinking about it, I launch an update on Zeal to have the newest doc from Ansible

- Trying to dissect every ~deploy.yml~ to understand how it works. Grafana uses docker so it will probably be easier
  - Beginning to make my own role
  - [[https://github.com/Marie-Donnie/ombt-orchestrator/commit/4907f1bea861e1fe0481604202dc526eca73b163][Twitched the conf file]]
    - Created a new branch
    - Changed remote url from https to ssh so I can push more quickly
  - [[https://github.com/Marie-Donnie/ombt-orchestrator/tree/tests/ansible/roles/cockroachdb/tasks][Made a bit of deploy]]
  - Going to launch a try to see where I screwed up
    - Ok, two persons took the entire Rennes site... so I'm switching to Nancy on grisou
      #+BEGIN_EXAMPLE
TASK [rabbitmq : Wait for the bus to be started] *******************************************************
ok: [grisou-33.nancy.grid5000.fr] => (item={'machine': u'grisou-33.nancy.grid5000.fr', 'management_port': 15672, 'port': 5672})

PLAY [Qpid dispatch deployment] ************************************************************************

TASK [qdr : include] ***********************************************************************************
skipping: [grisou-33.nancy.grid5000.fr]

PLAY RECAP *********************************************************************************************
grisou-32.nancy.grid5000.fr : ok=41   changed=9    unreachable=0    failed=0
grisou-33.nancy.grid5000.fr : ok=27   changed=7    unreachable=0    failed=0
grisou-39.nancy.grid5000.fr : ok=24   changed=6    unreachable=0    failed=0
grisou-49.nancy.grid5000.fr : ok=24   changed=6    unreachable=0    failed=0

{'code': 0, 'result': [{u'grisou-32.nancy.grid5000.fr': {'unreachable': 0, 'skipped': 1, 'ok': 41, 'changed': 9, 'failures': 0}}, {u'grisou-33.nancy.grid5000.fr': {'unreachable': 0, 'skipped': 2, 'ok': 27, 'changed': 7, 'failures': 0}}, {u'grisou-49.nancy.grid5000.fr': {'unreachable': 0, 'skipped': 1, 'ok': 24, 'changed': 6, 'failures': 0}}, {u'grisou-39.nancy.grid5000.fr': {'unreachable': 0, 'skipped': 1, 'ok': 24, 'changed': 6, 'failures': 0}}], 'playbook': 'ansible/site.yml'}
INFO:root:- Task prepare finished -
      #+END_EXAMPLE
    - Not much info on the error, I will ask Matthieu tomorrow
      - Ok after re-reading it, maybe I'm just missing to add the role in site.yml, and there was no error at all because cockroach wasn't in the file


** Fatima's Talk

Fatima did a talk called "Constructive privacy for shared genetic data" (cf talks dir)


* Friday 26 January [2018-01-26 ven.]

- Resumed tests

** Tests

- I've pulled the changes I made yesterday and I try to launch ombt-orchestrator with cockroachdb again
  #+BEGIN_SRC
  (venv) madelavergne@frennes:~/ombt-orchestrator$ ./cli.py deploy --provider=g5k rabbitmq
  #+END_SRC
  #+BEGIN_EXAMPLE
TASK [cockroachdb : Start cockroachdb] *****************************************************************
fatal: [parasilo-11.rennes.grid5000.fr]: FAILED! => {"failed": true, "msg": "The task includes an option with an undefined variable. The error was: 'item' is undefined\n\nThe error appears to have been in '/home/madelavergne/ombt-orchestrator/ansible/roles/cockroachdb/tasks/deploy.yml': line 1, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Start cockroachdb\n  ^ here\n"}
fatal: [parasilo-15.rennes.grid5000.fr]: FAILED! => {"failed": true, "msg": "The task includes an option with an undefined variable. The error was: 'item' is undefined\n\nThe error appears to have been in '/home/madelavergne/ombt-orchestrator/ansible/roles/cockroachdb/tasks/deploy.yml': line 1, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Start cockroachdb\n  ^ here\n"}
fatal: [parasilo-17.rennes.grid5000.fr]: FAILED! => {"failed": true, "msg": "The task includes an option with an undefined variable. The error was: 'item' is undefined\n\nThe error appears to have been in '/home/madelavergne/ombt-orchestrator/ansible/roles/cockroachdb/tasks/deploy.yml': line 1, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Start cockroachdb\n  ^ here\n"}
fatal: [parasilo-2.rennes.grid5000.fr]: FAILED! => {"failed": true, "msg": "The task includes an option with an undefined variable. The error was: 'item' is undefined\n\nThe error appears to have been in '/home/madelavergne/ombt-orchestrator/ansible/roles/cockroachdb/tasks/deploy.yml': line 1, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Start cockroachdb\n  ^ here\n"}
	to retry, use: --limit @/home/madelavergne/ombt-orchestrator/ansible/site.retry

PLAY RECAP *********************************************************************************************
parasilo-11.rennes.grid5000.fr : ok=42   changed=24   unreachable=0    failed=1
parasilo-15.rennes.grid5000.fr : ok=28   changed=18   unreachable=0    failed=1
parasilo-17.rennes.grid5000.fr : ok=25   changed=17   unreachable=0    failed=1
parasilo-2.rennes.grid5000.fr : ok=25   changed=17   unreachable=0    failed=1
  #+END_EXAMPLE

  + the error says that I didn't defined item
    - I saw it used elsewhere but I didn't see that Matthieu was defining the item for each task by
      #+BEGIN_SRC ansible
        with_items: "{{ ombt_confs[inventoy_hostname] }}"
      #+END_SRC
    - Changed that so I could rerun the test
      #+BEGIN_EXAMPLE
TASK [cockroachdb : Start cockroachdb] *****************************************************************
fatal: [parasilo-11.rennes.grid5000.fr]: FAILED! => {"failed": true, "msg": "'ombt_confs' is undefined"}
fatal: [parasilo-15.rennes.grid5000.fr]: FAILED! => {"failed": true, "msg": "'ombt_confs' is undefined"}
fatal: [parasilo-17.rennes.grid5000.fr]: FAILED! => {"failed": true, "msg": "'ombt_confs' is undefined"}
fatal: [parasilo-2.rennes.grid5000.fr]: FAILED! => {"failed": true, "msg": "'ombt_confs' is undefined"}
	to retry, use: --limit @/home/madelavergne/ombt-orchestrator/ansible/site.retry
      #+END_EXAMPLE

  + Changed the file again to use ~inventory_hostname~
    #+BEGIN_EXAMPLE
    PLAY [CockroachDB] *************************************************************************************

TASK [cockroachdb : include] ***************************************************************************
included: /home/madelavergne/ombt-orchestrator/ansible/roles/cockroachdb/tasks/deploy.yml for parasilo-11.rennes.grid5000.fr, parasilo-15.rennes.grid5000.fr, parasilo-17.rennes.grid5000.fr, parasilo-2.rennes.grid5000.fr

TASK [cockroachdb : Start cockroachdb] *****************************************************************
changed: [parasilo-2.rennes.grid5000.fr]
changed: [parasilo-15.rennes.grid5000.fr]
changed: [parasilo-11.rennes.grid5000.fr]
changed: [parasilo-17.rennes.grid5000.fr]

PLAY RECAP *********************************************************************************************
parasilo-11.rennes.grid5000.fr : ok=43   changed=10   unreachable=0    failed=0
parasilo-15.rennes.grid5000.fr : ok=29   changed=8    unreachable=0    failed=0
parasilo-17.rennes.grid5000.fr : ok=26   changed=7    unreachable=0    failed=0
parasilo-2.rennes.grid5000.fr : ok=26   changed=7    unreachable=0    failed=0

{'code': 0, 'result': [{u'parasilo-17.rennes.grid5000.fr': {'unreachable': 0, 'skipped': 1, 'ok': 26, 'changed': 7, 'failures': 0}}, {u'parasilo-15.rennes.grid5000.fr': {'unreachable': 0, 'skipped': 2, 'ok': 29, 'changed': 8, 'failures': 0}}, {u'parasilo-2.rennes.grid5000.fr': {'unreachable': 0, 'skipped': 1, 'ok': 26, 'changed': 7, 'failures': 0}}, {u'parasilo-11.rennes.grid5000.fr': {'unreachable': 0, 'skipped': 1, 'ok': 43, 'changed': 10, 'failures': 0}}], 'playbook': 'ansible/site.yml'}
INFO:root:- Task prepare finished -
    #+END_EXAMPLE

  + So, I passed this step, but now I have to test exactly what I've done with these cockroach containers

    #+BEGIN_EXAMPLE
    root@parasilo-17:~# docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
d45265172b80        telegraf            "/entrypoint.sh tele…"   About an hour ago   Up 24 minutes                           telegraf
root@parasilo-17:~# docker ps -a
CONTAINER ID        IMAGE                          COMMAND                  CREATED             STATUS                      PORTS               NAMES
3378303bacb9        cockroachdb/cockroach:v1.1.4   "/cockroach/cockroac…"   3 minutes ago       Created                                         roach1
ea9bcebe9f22        cockroachdb/cockroach          "/cockroach/cockroac…"   24 minutes ago      Exited (1) 24 minutes ago                       cockroachdb
d45265172b80        telegraf                       "/entrypoint.sh tele…"   About an hour ago   Up 25 minutes                                   telegraf
root@parasilo-17:~# docker restart ea9bcebe9f22
ea9bcebe9f22
root@parasilo-17:~# docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
d45265172b80        telegraf            "/entrypoint.sh tele…"   About an hour ago   Up 25 minutes                           telegraf
root@parasilo-17:~# docker ps -a
CONTAINER ID        IMAGE                          COMMAND                  CREATED             STATUS                     PORTS               NAMES
3378303bacb9        cockroachdb/cockroach:v1.1.4   "/cockroach/cockroac…"   4 minutes ago       Created                                        roach1
ea9bcebe9f22        cockroachdb/cockroach          "/cockroach/cockroac…"   25 minutes ago      Exited (1) 8 seconds ago                       cockroachdb
d45265172b80        telegraf                       "/entrypoint.sh tele…"   About an hour ago   Up 26 minutes                                  telegraf
root@parasilo-17:~# docker logs ea9bcebe9f22
Error: unknown command "cockroachdb/cockroach:v1.1.4" for "cockroach"
Run 'cockroach --help' for usage.
Failed running "cockroachdb/cockroach:v1.1.4"
Error: unknown command "cockroachdb/cockroach:v1.1.4" for "cockroach"
Run 'cockroach --help' for usage.
Failed running "cockroachdb/cockroach:v1.1.4"
    #+END_EXAMPLE
    - Changed the deploy to remove the version and to only have ~cockroach start~ in the command but
      #+BEGIN_EXAMPLE
Error: unknown command "cockroach" for "cockroach"
Run 'cockroach --help' for usage.
Failed running "cockroach"
Error: unknown command "cockroach" for "cockroach"
Run 'cockroach --help' for usage.
Failed running "cockroach"
      #+END_EXAMPLE
    - I fail to see why ansible can't read the entire command with or without quotes, so I'm reading the book Ronan told me about
    - Ok, after asking Matthieu, turns out I didn't need to put "cockroach" at the beginning of the command, so
      #+BEGIN_SRC ansible
      command: start --insecure
      #+END_SRC
    - This way, it went smoothly
  + Now I'll try to do stuff on cockroachdb. It shouldn't work on the db on other nodes, but you never know unless you've tried :)
    - After following the tutorial on one node with
      #+BEGIN_SRC
      docker exec -it cockroach ./cockroach sql --insecure
      #+END_SRC
    - On another node:
      #+BEGIN_EXAMPLE
root@:26257/> SELECT * FROM bank.accounts;
pq: database "bank" does not exist
      #+END_EXAMPLE
    - Now, at least, I'm sure of it :D
  + I think I need to give another name to a /master/ and then join him on the network on the other nodes
    - Now I have to search how to do this
      + I'll probably need to make two cases: the default and the master
      + To do so, I have to change the ~conf.yaml~ to add a role cockroach-master
    - After a bit of fighting, I managed to have no visible errors, but my master was skipped
      + Of course, lost another hour because I wrote "cochroachdb-master" on conf.yaml...
    - Now I'll test the db again
      + on the master:
      #+BEGIN_EXAMPLE
      root@paravance-26:~# docker exec -it cockroachdb-master ./cockroach sql --insecure
      #+END_EXAMPLE
      + on a node:
      #+BEGIN_EXAMPLE
root@paravance-31:~# docker exec -it cockroachdb-paravance-31.rennes.grid5000.fr ./cockroach sql --insecure
# Welcome to the cockroach SQL interface.
# All statements must be terminated by a semicolon.
# To exit: CTRL + D.
#
Error: unable to connect or connection lost.

Please check the address and credentials such as certificates (if attempting to
communicate with a secure cluster).

read tcp 127.0.0.1:36522->127.0.0.1:26257: read: connection reset by peer
Failed running "sql"

      #+END_EXAMPLE
      + Reran the deployment but nothing has changed, so I'll probably have to change the deploys.yml

  + Ronan told me to put the ip of the master in the join, which kind of worked:
    - I can connect to the "slave" databases
      #+BEGIN_EXAMPLE
root@paravance-29:~# docker exec -it cockroachdb-paravance-29.rennes.grid5000.fr ./cockroach sql --insecure
# Welcome to the cockroach SQL interface.
# All statements must be terminated by a semicolon.
# To exit: CTRL + D.
#
# Server version: CockroachDB CCL v1.1.4 (linux amd64, built 2018/01/08 17:32:42, go1.8.3) (same version as client)
# Cluster ID: cec2c481-e688-4a70-a8f7-a047149eedbb
#
# Enter \? for a brief introduction.
#
      #+END_EXAMPLE
    - I can't do (on p29):
      #+BEGIN_EXAMPLE
root@:26257/> SELECT * FROM bank.accounts;
pq: no inbound stream connection
      #+END_EXAMPLE
    - BUT the database has indeed been replicated (p29):
      #+BEGIN_EXAMPLE
root@:26257/> SHOW DATABASES;
+--------------------+
|      Database      |
+--------------------+
| bank               |
| crdb_internal      |
| information_schema |
| pg_catalog         |
| system             |
+--------------------+
(5 rows)

Time: 1.399093ms
      #+END_EXAMPLE
      #+BEGIN_EXAMPLE
root@:26257/> SHOW COLUMNS FROM bank.accounts;
+---------+---------+-------+---------+-------------+
|  Field  |  Type   | Null  | Default |   Indices   |
+---------+---------+-------+---------+-------------+
| id      | INT     | false | NULL    | {"primary"} |
| balance | DECIMAL | true  | NULL    | {}          |
+---------+---------+-------+---------+-------------+
(2 rows)

Time: 7.1018ms
      #+END_EXAMPLE

- Did a bit of testings to see how it works:
  + (p26-master)
    #+BEGIN_EXAMPLE
root@:26257/> INSERT INTO bank.accounts VALUES (2, 3);
INSERT 1

Time: 23.004289ms

root@:26257/> SELECT * FROM bank.accounts;
+----+---------+
| id | balance |
+----+---------+
|  1 | 1000.50 |
|  2 |       3 |
+----+---------+
(2 rows)

Time: 808.705µs
    #+END_EXAMPLE
  + (p29)
    #+BEGIN_EXAMPLE
root@:26257/> SELECT * FROM bank.accounts;
pq: no inbound stream connection
root@:26257/> INSERT INTO bank.accounts VALUES (3, 42);
INSERT 1

Time: 23.88463ms

root@:26257/> SELECT * FROM bank.accounts;
pq: no inbound stream connection
    #+END_EXAMPLE
  + (p26-master)
    #+BEGIN_EXAMPLE
root@:26257/> SELECT * FROM bank.accounts;
+----+---------+
| id | balance |
+----+---------+
|  1 | 1000.50 |
|  2 |       3 |
|  3 |      42 |
+----+---------+
(3 rows)

Time: 951.275µs
    #+END_EXAMPLE
  + This means IT WORKS! \o/
    - I have to check though, if it's normal to be able to read only on the master and write on all replicas
    - After searching for a bit, I recalled that it was actually supposed to work in the tutorial
    - So I still have to dig deeper

  + Ronan told me to just try to deploy the dockers on two machines on g5k with a oarsub -I to avoid long waitings, and launch the command without =hostname= and =network_mode=
    - Tried to do this quickly, but I'll have to install docker, so I'll either lauch ombt-orchestrator without all the roles or I will have to install docker on a reservation to have some time because right now I don't have enough time to make a reservation and do the work before nightly bookings.
