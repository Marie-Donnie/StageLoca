#+TITLE: Report for : Un intergiciel d’une base de données NewSQL qui considère la localité de l’application cliente -- 4th week --
#+AUTHOR: Marie Delavergne

* Monday 5 February [2018-02-05 lun.]

- Been thinking about adding vars in =extra_vars= during the ~prepare~ task but I don't think it would be a good way
- The other solution I thought about was to add vars in the beginning of the sysbench ~deploy~, depending on the 'db' var

- For now, I will concentrate on making everything work and then I will see about making it the proper way

- Added the run to the deployment
#+BEGIN_EXAMPLE
root@parapluie-25:~# docker logs sysbench
sysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)

Running the test with following options:
Number of threads: 1
Initializing random number generator from current time


Initializing worker threads...

Threads started!

SQL statistics:
    queries performed:
        read:                            2646
        write:                           360
        other:                           774
        total:                           3780
    transactions:                        189    (18.83 per sec.)
    queries:                             3780   (376.60 per sec.)
    ignored errors:                      0      (0.00 per sec.)
    reconnects:                          0      (0.00 per sec.)

General statistics:
    total time:                          10.0351s
    total number of events:              189

Latency (ms):
         min:                                 32.82
         avg:                                 53.08
         max:                                391.95
         95th percentile:                     95.81
         sum:                              10032.55

Threads fairness:
    events (avg/stddev):           189.0000/0.00
    execution time (avg/stddev):   10.0326/0.00
#+END_EXAMPLE

- Now, doing the same with CockroachDB
  + Using [[https://www.cockroachlabs.com/docs/stable/use-the-built-in-sql-client.html][Cockroach doc]]
    #+BEGIN_EXAMPLE
root@parapluie-1:~# docker exec -d cockroachdb-master cockroach sql --insecure --execute="CREATE DATABASE sbtest;"
Error response from daemon: OCI runtime exec failed: exec failed: container_linux.go:296: starting container process caused "exec: \"cockroach\": executable file not found in $PATH": unknown
    #+END_EXAMPLE

** Meeting with Matthieu

For cockroach:
- Know where the request has been

For everything:
- Get disk I/O


** Refactoring with Ronan

- Corrected command [[https://github.com/Marie-Donnie/juice/commit/41526a257ef686958c9ff9429644d7a81c6b8a1c][to create database]]
  + Ok but breaks the other nodes since they don't have a cockroach-master docker
- Did a bit of refactoring to avoid duplicated code [[https://github.com/Marie-Donnie/juice/commit/edaebe2e5b6032a0e54c2eb62b64476f3d91112f][here]]
  + Trying to deploy that version now


* Tuesday 6 February [2018-02-06 mar.]

** Meeting with Ronan and Adrien

- About the tests we are going to do

- Reminder:
  #+BEGIN_QUOTE
- several regions
  + common authentication
  + number of regions: 1, 5, 10, 25, (100?)
  + latency between regions (RTT): LAN, 10, 50, 100, 300
    - 1 common keystone
      + one region has the keystone
      + the others refers to this keystone
      + one database
    - 1 keystone per region with a common state
      + Galera vs CockroachDB
    - 1 keystone per region using K2K federation
  #+END_QUOTE

- Adrien is ok with this, so we can resume our work

** Tests

- When deploying yesterday afternoon, I forgot to add the host ip for sysbench deployment
  - ok
    #+BEGIN_EXAMPLE
root@grisou-40:~# docker logs sysbench
sysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)

Running the test with following options:
Number of threads: 1
Initializing random number generator from current time


Initializing worker threads...

Threads started!

SQL statistics:
    queries performed:
        read:                            1204
        write:                           86
        other:                           430
        total:                           1720
    transactions:                        86     (8.56 per sec.)
    queries:                             1720   (171.15 per sec.)
    ignored errors:                      0      (0.00 per sec.)
    reconnects:                          0      (0.00 per sec.)

General statistics:
    total time:                          10.0473s
    total number of events:              86

Latency (ms):
         min:                                 97.29
         avg:                                116.82
         max:                                148.84
         95th percentile:                    142.39
         sum:                              10046.54

Threads fairness:
    events (avg/stddev):           86.0000/0.00
    execution time (avg/stddev):   10.0465/0.00
    #+END_EXAMPLE

** Planning

- We prepared a planning for the work to do:
*** summit deadline
    DEADLINE: <2018-02-08 jeu.>
*** be able to backup the results
    DEADLINE: <2018-02-09 ven.>
*** end of tests
    DEADLINE: <2018-03-30 ven.>
*** summit
    SCHEDULED: <2018-05-21 lun.>

*** Making it work

- To do so, I have to look at how we are going to collect informations about CockroachDB and MariaDB
  + For MariaDB, it will probably be [[https://collectd.org/documentation/manpages/collectd.conf.5.shtml#plugin_mysql][collectd]] ( [[http://ftp.nchu.edu.tw/MySQL/doc/refman/5.0/en/server-status-variables.html][server status variables]] )
  + For CockroachDB, we have several leads:
    - [[https://www.cockroachlabs.com/docs/stable/monitor-cockroachdb-with-prometheus.html][Monitor CockroachDB with Prometheus]]
      + config file setups prometheus so he will scrape the time series metrics of a single, insecure local node every 10 seconds : [[https://github.com/cockroachdb/cockroach/blob/master/monitoring/prometheus.yml][default config file]]
	- I can check for several nodes using =targets=
	- I can also change the interval using =scrape_interval=
    - [[https://www.cockroachlabs.com/docs/stable/show-sessions.html][MySQL API]] (=SHOW <OPTION>=)
      + Session seems promising because it gives the node it is connected to, the queries and the timestamp
	- Can be used with =SHOW SESSIONS= (cluster) or =SHOW LOCAL SESSIONS= (local)
      + =SHOW QUERIES= is even more interesting because
	- it gives informations about:
	  + where the query is executed
	  + the query, ofc
	  + how long it has been running
	  + informations about the client that issued the query (address, application name and user)
        - so I can use this database to track both where it comes from and where it is executed
	- I can also track if the query is distributed using [[https://github.com/cockroachdb/cockroach/blob/master/docs/RFCS/20160421_distributed_sql.md][DistSQL]]
    - Find if there is a rest API [[https://github.com/cockroachdb/cockroach/pull/4844][like that]]
    - Use collectd also

** Make a better juice

- I am going to use docopt, which I already used for [[https://github.com/Marie-Donnie/rally-vagrant][Rally Vagrant]]
  + It takes a bit longer than I anticipated/remembered so I am putting this aside for now (=no_push= folder)
  + I will try it again when everything will be ok

- Testing the "creates" option for command so the creation of the database sbtest won't be done twice when deploying with CockroachDB
  + used
    #+BEGIN_SRC
args:
    creates: /database_created
    #+END_SRC
    - works the first launch
    - didn't worked at second launch
      #+BEGIN_EXAMPLE
      fatal: [grisou-16.nancy.grid5000.fr]: FAILED! => {"changed": true, "cmd": ["docker", "exec", "cockroachdb-grisou-16", "./cockroach", "sql", "--insecure", "--execute=CREATE DATABASE sbtest;"], "delta": "0:00:05.424156", "end": "2018-02-06 16:13:31.697221", "failed": true, "rc": 1, "start": "2018-02-06 16:13:26.273065", "stderr": "Error: pq: database \"sbtest\" already exists\nFailed running \"sql\"", "stderr_lines": ["Error: pq: database \"sbtest\" already exists", "Failed running \"sql\""], "stdout": "", "stdout_lines": []}
      #+END_EXAMPLE
  + tried
    #+BEGIN_SRC
      run_once: True
    #+END_SRC
    - same problem
  + works when creating the file manually... will have to debug this + I will probably need to do the same for the test anyway because the sysbench doesn't like restarts:
    #+BEGIN_EXAMPLE
    root@grisou-34:~# docker logs sysbench
sysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)

Running the test with following options:
Number of threads: 1
Initializing random number generator from current time


Initializing worker threads...

Threads started!

FATAL: PQexecPrepared() failed: 7 restart transaction: HandledRetryableTxnError: TransactionRetryError: retry txn (RETRY_POSSIBLE_REPLAY): "sql txn" id=6b1397fd key=/Table/51/1/503120 rw=false pri=0.02027573 iso=SERIALIZABLE stat=PENDING epo=0 ts=1517933446.189282943,1 orig=1517933446.187652172,0 max=1517933446.187652172,0 wto=false rop=false seq=16
FATAL: `thread_run' function failed: /usr/share/sysbench/oltp_common.lua:481: SQL error, errno = 0, state = '40001': restart transaction: HandledRetryableTxnError: TransactionRetryError: retry txn (RETRY_POSSIBLE_REPLAY): "sql txn" id=6b1397fd key=/Table/51/1/503120 rw=false pri=0.02027573 iso=SERIALIZABLE stat=PENDING epo=0 ts=1517933446.189282943,1 orig=1517933446.187652172,0 max=1517933446.187652172,0 wto=false rop=false seq=16
    #+END_EXAMPLE

- Looking to use json format for reports
  + Still haven't figured it out when reading from:
    - [[https://github.com/akopytov/sysbench/blob/master/src/lua/internal/sysbench.lua#L91][The implemented function]]
    - I don't understand how this is called and whether the default is called at all since this format isn't the kind of output I get
    - I still probably have to use [[https://mariadb.com/kb/en/library/sysbench-benchmark-setup/][MariaDB sysbench benchmark setup]] but they use their own lua scripts it seems

* Wednesday 7 February [2018-02-07 mer.]

- MySQL plugin for [[https://collectd.org/documentation/manpages/collectd.conf.5.shtml#plugin_mysql][collectd]] collects information about MySQL network traffic, executed statements, requests, query cache and threads using (from [[http://ftp.nchu.edu.tw/MySQL/doc/refman/5.0/en/server-status-variables.html#statvar_Bytes_received][source]]):
  + =bytes (received/sent)=: the number of bytes received from/sent to all clients
  + =com_<statement>=: number of time each statement (insert/delete, etc.) has been executed. For select, it uses =qcache_hits=
  + =handler_<statement>=: number of time <statement> happened (e.g. read next, prepare, rollback)
  + =qcache_<query/count>=: data relative to the query cache (e.g. inserts, hits, total blocks)
  + =thread_<state>=: number of threads in that state (cached, connected, created, running)

** About juice

- Using =posgtresql_db= module for Ansible instead of the command module to insert a database on CockroachDB
  + first time: works like a charm
    #+BEGIN_EXAMPLE
    root@:26257/> SHOW DATABASES;
+--------------------+
|      Database      |
+--------------------+
| crdb_internal      |
| information_schema |
| pg_catalog         |
| sbtest             |
| system             |
+--------------------+
(5 rows)

Time: 1.965848ms
    #+END_EXAMPLE
  + second time:
    #+BEGIN_EXAMPLE
    TASK [sysbench : Create CockroachDB sbtest database for sysbench] **************************************
fatal: [grisou-16.nancy.grid5000.fr]: FAILED! => {"changed": false, "failed": true, "msg": "Database query failed: unknown function: pg_encoding_to_char()\n"}
    #+END_EXAMPLE
  + tried =encoding: 'UTF-8'= but it didn't help, some I removed it.
  + in any case, best thing to do is probably use =destroy= when redeploying
    - Ronan does not agree because when I will put OpenStack on top of the deployment, it will be much too long
    - So we're going to change the play so it won't produce an error after the first deployment
    - We also did "a bit" of changes to finally use docopt: [[https://github.com/Marie-Donnie/juice/commit/0625cc40b8edd0569d578ccac271a4fa534418f4][commit]]


** Thinking about the proposal for the summit



The Fog/Edge Massively Distributed Clouds (FEMDC) working group is trying to monitor how OpenStack will behave in the context of compute resources close to users.

To see how the Keystone service will handle authentication on a varying number of regions and throughout the variation of latency between those regions, we evaluated the performances over different configurations:
- One centralized Keystone on a single region, handling the others requests
- A replicated Keystone throughout the cluster with a common state, comparing MariaDB Galera Cluster and CockroachDB
- A federated Keystone
This presentation exhibits the methodology, the results and the identification of the possible improvements towards a massively distributed OpenStack.

*** sources

- [[https://docs.openstack.org/security-guide/identity/federated-keystone.html][federated keystone]]
- [[https://mariadb.com/kb/en/library/what-is-mariadb-galera-cluster/][mariadb galera cluster]]
